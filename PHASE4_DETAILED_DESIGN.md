# Phase 4 è¯¦ç»†è®¾è®¡æ–‡æ¡£ï¼šæ•°æ®åˆ†æ + å¯è§†åŒ–

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0
**åˆ›å»ºæ—¥æœŸ**: 2026-02-14
**ç›®æ ‡å—ä¼—**: AI ç¼–ç¨‹å®æ–½
**å®æ–½å·¥æœŸ**: 3 å‘¨ï¼ˆ15 ä¸ªå·¥ä½œæ—¥ï¼‰
**å‰ç½®ä¾èµ–**: Phase 3 å®Œæˆ âœ…

---

## ğŸ“‘ ç›®å½•

1. [è®¾è®¡æ€»è§ˆ](#1-è®¾è®¡æ€»è§ˆ)
2. [æ•°æ®åº“è®¾è®¡](#2-æ•°æ®åº“è®¾è®¡)
3. [æ¨¡å—è¯¦ç»†è®¾è®¡](#3-æ¨¡å—è¯¦ç»†è®¾è®¡)
4. [æ¥å£è§„èŒƒ](#4-æ¥å£è§„èŒƒ)
5. [é…ç½®è®¾è®¡](#5-é…ç½®è®¾è®¡)
6. [æµ‹è¯•è®¾è®¡](#6-æµ‹è¯•è®¾è®¡)
7. [å®æ–½ä»»åŠ¡æ¸…å•](#7-å®æ–½ä»»åŠ¡æ¸…å•)
8. [éªŒæ”¶æ ‡å‡†](#8-éªŒæ”¶æ ‡å‡†)

---

## 1. è®¾è®¡æ€»è§ˆ

### 1.1 ç›®æ ‡ä¸èŒƒå›´

**Phase 4 ç›®æ ‡**ï¼šå°† Phase 3 é‡‡é›†çš„æ•°æ®è½¬åŒ–ä¸ºå¯è§†åŒ–æ´å¯Ÿå’Œåˆ†ææŠ¥å‘Š

**æ ¸å¿ƒåŠŸèƒ½ï¼ˆ5 ä¸ªæ¨¡å—ï¼‰**ï¼š
1. âœ… **å›¾ç‰‡å…ƒæ•°æ®åˆ†æ**ï¼šEXIF æå–ã€æ°´å°æ˜¾ç¤ºã€GPS åˆ†æ
2. âœ… **æ–‡æœ¬åˆ†æ**ï¼šè¯äº‘ç”Ÿæˆã€å…³é”®è¯æå–
3. âœ… **æ—¶é—´åˆ†æ**ï¼šè¶‹åŠ¿å›¾ã€çƒ­åŠ›å›¾ã€æ´»è·ƒåº¦åˆ†æ
4. âœ… **å¯è§†åŒ–å¢å¼º**ï¼šå›¾è¡¨ç¾åŒ–ã€ä¸­æ–‡æ”¯æŒ
5. âœ… **æŠ¥å‘Šç”Ÿæˆ**ï¼šHTML æŠ¥å‘Šè‡ªåŠ¨ç”Ÿæˆ

**éç›®æ ‡ï¼ˆPhase 5ï¼‰**ï¼š
- âŒ äº¤äº’å¼å¯è§†åŒ–ï¼ˆplotlyï¼‰
- âŒ PDF å¯¼å‡º
- âŒ Web ç•Œé¢

### 1.2 æŠ€æœ¯æ ˆ

**æ ¸å¿ƒä¾èµ–**ï¼š
```python
# requirements.txt æ–°å¢
Pillow>=10.0.0        # å›¾ç‰‡å¤„ç†ã€EXIF æå–
jieba>=0.42.0         # ä¸­æ–‡åˆ†è¯
wordcloud>=1.9.0      # è¯äº‘ç”Ÿæˆ
matplotlib>=3.7.0     # å›¾è¡¨ç»˜åˆ¶
seaborn>=0.12.0       # é«˜çº§å¯è§†åŒ–ï¼ˆçƒ­åŠ›å›¾ï¼‰
pandas>=2.0.0         # æ•°æ®å¤„ç†
jinja2>=3.1.0         # HTML æ¨¡æ¿
geopy>=2.3.0          # GPS åæŸ¥
```

**å­—ä½“ä¾èµ–**ï¼ˆå¿…éœ€ï¼‰ï¼š
- Linux: `apt install fonts-wqy-zenhei`
- macOS: ç³»ç»Ÿè‡ªå¸¦é»‘ä½“
- Windows: ç³»ç»Ÿè‡ªå¸¦å¾®è½¯é›…é»‘

### 1.3 æ¨¡å—æ¶æ„

```
python/src/
â”œâ”€â”€ analysis/                    # æ–°å¢ï¼šåˆ†ææ¨¡å—
â”‚   â”œâ”€â”€ __init__.py             # æ¨¡å—å¯¼å‡º
â”‚   â”œâ”€â”€ exif_analyzer.py        # EXIF åˆ†æå™¨ï¼ˆæ–°å¢ï¼‰
â”‚   â”œâ”€â”€ text_analyzer.py        # æ–‡æœ¬åˆ†æå™¨ï¼ˆæ–°å¢ï¼‰
â”‚   â”œâ”€â”€ time_analyzer.py        # æ—¶é—´åˆ†æå™¨ï¼ˆæ–°å¢ï¼‰
â”‚   â”œâ”€â”€ visualizer.py           # å¯è§†åŒ–å™¨ï¼ˆæ–°å¢ï¼‰
â”‚   â””â”€â”€ report_generator.py     # æŠ¥å‘Šç”Ÿæˆå™¨ï¼ˆæ–°å¢ï¼‰
â”‚
â”œâ”€â”€ database/                    # æ‰©å±•ï¼šæ•°æ®åº“æ¨¡å—
â”‚   â”œâ”€â”€ schema_v2.sql           # Schema æ‰©å±•è„šæœ¬ï¼ˆæ–°å¢ï¼‰
â”‚   â”œâ”€â”€ migrate_exif.py         # EXIF æ•°æ®è¿ç§»ï¼ˆæ–°å¢ï¼‰
â”‚   â””â”€â”€ models.py               # æ‰©å±• Media æ¨¡å‹
â”‚
â”œâ”€â”€ scraper/                     # æ‰©å±•ï¼šçˆ¬è™«æ¨¡å—
â”‚   â”œâ”€â”€ downloader.py           # æ‰©å±•ï¼šä¸‹è½½æ—¶æå– EXIF
â”‚   â””â”€â”€ archiver.py             # æ‰©å±•ï¼šHTML ç”Ÿæˆæ·»åŠ æ°´å°
â”‚
â”œâ”€â”€ menu/                        # æ‰©å±•ï¼šèœå•æ¨¡å—
â”‚   â”œâ”€â”€ main_menu.py            # æ‰©å±•ï¼šæ·»åŠ åˆ†æèœå•å…¥å£
â”‚   â””â”€â”€ analysis_menu.py        # åˆ†æèœå•ï¼ˆæ–°å¢ï¼‰
â”‚
â””â”€â”€ utils/                       # æ‰©å±•ï¼šå·¥å…·æ¨¡å—
    â”œâ”€â”€ exif_utils.py           # EXIF å·¥å…·å‡½æ•°ï¼ˆæ–°å¢ï¼‰
    â”œâ”€â”€ font_config.py          # å­—ä½“é…ç½®ï¼ˆæ–°å¢ï¼‰
    â””â”€â”€ stopwords.txt           # åœç”¨è¯è¡¨ï¼ˆæ–°å¢ï¼‰
```

**è¾“å‡ºç›®å½•**ï¼š
```
åˆ†ææŠ¥å‘Š/
â”œâ”€â”€ wordcloud/                  # è¯äº‘å›¾
â”‚   â”œâ”€â”€ ç‹¬é†‰ç¬‘æ¸…é£_wordcloud.png
â”‚   â”œâ”€â”€ æ¸…é£çš“æœˆ_wordcloud.png
â”‚   â””â”€â”€ å…¨å±€_wordcloud.png
â”‚
â”œâ”€â”€ charts/                     # ç»Ÿè®¡å›¾è¡¨
â”‚   â”œâ”€â”€ monthly_trend.png
â”‚   â”œâ”€â”€ time_heatmap.png
â”‚   â””â”€â”€ camera_ranking.png
â”‚
â””â”€â”€ reports/                    # HTML æŠ¥å‘Š
    â”œâ”€â”€ index.html              # æ¦‚è§ˆé¡µ
    â”œâ”€â”€ author_ç‹¬é†‰ç¬‘æ¸…é£.html
    â””â”€â”€ author_æ¸…é£çš“æœˆ.html
```

---

## 2. æ•°æ®åº“è®¾è®¡

### 2.1 Schema æ‰©å±•

**æ–‡ä»¶**: `python/src/database/schema_v2.sql`

```sql
-- Phase 4: æ‰©å±• media è¡¨ï¼Œæ·»åŠ  EXIF å­—æ®µ
-- æ‰§è¡Œæ—¶æœºï¼šPhase 4 å¯åŠ¨æ—¶è‡ªåŠ¨æ£€æµ‹å¹¶æ‰§è¡Œ

-- æ£€æŸ¥æ˜¯å¦å·²æ‰©å±•
-- SELECT COUNT(*) FROM pragma_table_info('media') WHERE name = 'exif_make';

-- EXIF åŸºç¡€ä¿¡æ¯
ALTER TABLE media ADD COLUMN exif_make TEXT;           -- ç›¸æœºå“ç‰Œ
ALTER TABLE media ADD COLUMN exif_model TEXT;          -- ç›¸æœºå‹å·
ALTER TABLE media ADD COLUMN exif_datetime TEXT;       -- æ‹æ‘„æ—¶é—´

-- EXIF æ‹æ‘„å‚æ•°
ALTER TABLE media ADD COLUMN exif_iso INTEGER;         -- ISO æ„Ÿå…‰åº¦
ALTER TABLE media ADD COLUMN exif_aperture REAL;       -- å…‰åœˆå€¼
ALTER TABLE media ADD COLUMN exif_shutter_speed TEXT;  -- å¿«é—¨é€Ÿåº¦
ALTER TABLE media ADD COLUMN exif_focal_length REAL;   -- ç„¦è·

-- GPS ä¿¡æ¯
ALTER TABLE media ADD COLUMN exif_gps_lat REAL;        -- GPS çº¬åº¦
ALTER TABLE media ADD COLUMN exif_gps_lng REAL;        -- GPS ç»åº¦
ALTER TABLE media ADD COLUMN exif_location TEXT;       -- åœ°ç†ä½ç½®ï¼ˆåæŸ¥ï¼‰

-- åˆ›å»ºç´¢å¼•ï¼ˆä¼˜åŒ–æŸ¥è¯¢ï¼‰
CREATE INDEX IF NOT EXISTS idx_media_exif_make ON media(exif_make);
CREATE INDEX IF NOT EXISTS idx_media_exif_model ON media(exif_model);
CREATE INDEX IF NOT EXISTS idx_media_exif_datetime ON media(exif_datetime);
CREATE INDEX IF NOT EXISTS idx_media_gps ON media(exif_gps_lat, exif_gps_lng);

-- åˆ›å»ºè§†å›¾ï¼šç›¸æœºä½¿ç”¨ç»Ÿè®¡
CREATE VIEW IF NOT EXISTS v_camera_stats AS
SELECT
    exif_make,
    exif_model,
    COUNT(*) as photo_count,
    COUNT(DISTINCT post_id) as post_count,
    MIN(exif_datetime) as first_use,
    MAX(exif_datetime) as last_use
FROM media
WHERE media_type = 'image'
  AND exif_make IS NOT NULL
  AND exif_model IS NOT NULL
GROUP BY exif_make, exif_model
ORDER BY photo_count DESC;

-- åˆ›å»ºè§†å›¾ï¼šæ‹æ‘„åœ°ç‚¹ç»Ÿè®¡
CREATE VIEW IF NOT EXISTS v_location_stats AS
SELECT
    exif_location,
    COUNT(*) as photo_count,
    COUNT(DISTINCT post_id) as post_count,
    AVG(exif_gps_lat) as avg_lat,
    AVG(exif_gps_lng) as avg_lng
FROM media
WHERE media_type = 'image'
  AND exif_location IS NOT NULL
GROUP BY exif_location
ORDER BY photo_count DESC;
```

### 2.2 æ•°æ®è¿ç§»ç­–ç•¥

**ç›®æ ‡**ï¼šæ‰«æå·²æœ‰å›¾ç‰‡ï¼Œæå– EXIF å…ƒæ•°æ®å¹¶å†™å…¥æ•°æ®åº“

**æµç¨‹**ï¼š
1. æŸ¥è¯¢æ‰€æœ‰ `media_type='image'` ä¸” `exif_make IS NULL` çš„è®°å½•
2. æŒ‰ `file_path` è¯»å–å›¾ç‰‡æ–‡ä»¶
3. æå– EXIF æ•°æ®
4. æ‰¹é‡æ›´æ–°æ•°æ®åº“ï¼ˆ100 æ¡/æ‰¹æ¬¡ï¼‰
5. æ˜¾ç¤ºè¿›åº¦æ¡

**æ€§èƒ½è¦æ±‚**ï¼š
- æ‰«æé€Ÿåº¦ï¼š> 10 å¼ /ç§’
- 1,000 å¼ å›¾ç‰‡ï¼š< 2 åˆ†é’Ÿ

**å®¹é”™å¤„ç†**ï¼š
- æ–‡ä»¶ä¸å­˜åœ¨ï¼šè®°å½•æ—¥å¿—ï¼Œè·³è¿‡
- EXIF æ•°æ®ç¼ºå¤±ï¼šå­—æ®µè®¾ä¸º NULLï¼Œä¸æŠ¥é”™
- GPS åæŸ¥å¤±è´¥ï¼šä¿å­˜åæ ‡ï¼Œlocation ä¸º NULL

---

## 3. æ¨¡å—è¯¦ç»†è®¾è®¡

### 3.1 EXIF åˆ†æå™¨ï¼ˆexif_analyzer.pyï¼‰

**èŒè´£**ï¼šæå–å’Œåˆ†æå›¾ç‰‡ EXIF å…ƒæ•°æ®

#### 3.1.1 æ ¸å¿ƒç±»è®¾è®¡

```python
"""
EXIF åˆ†æå™¨æ¨¡å—

åŠŸèƒ½ï¼š
1. æå–å›¾ç‰‡ EXIF å…ƒæ•°æ®
2. GPS åæ ‡åæŸ¥åœ°ç†ä½ç½®
3. ç»Ÿè®¡ç›¸æœºä½¿ç”¨æƒ…å†µ
4. åˆ†ææ‹æ‘„å‚æ•°åˆ†å¸ƒ

ä¾èµ–ï¼š
- Pillow (PIL)
- geopy

ä½œè€…: Claude Sonnet 4.5
æ—¥æœŸ: 2026-02-14
"""

from typing import Dict, Optional, Tuple, List
from pathlib import Path
from PIL import Image
from PIL.ExifTags import TAGS, GPSTAGS
import logging
from geopy.geocoders import Nominatim
from geopy.exc import GeocoderTimedOut, GeocoderServiceError
import time

logger = logging.getLogger(__name__)


class ExifAnalyzer:
    """EXIF æ•°æ®åˆ†æå™¨"""

    def __init__(self, db_connection=None):
        """
        åˆå§‹åŒ– EXIF åˆ†æå™¨

        Args:
            db_connection: æ•°æ®åº“è¿æ¥ï¼ˆå¯é€‰ï¼‰
        """
        self.db = db_connection
        self.geolocator = Nominatim(
            user_agent="t66y-forum-archiver/1.0",
            timeout=10
        )
        # GPS åæŸ¥ç¼“å­˜ï¼ˆé¿å…é‡å¤æŸ¥è¯¢ï¼‰
        self._location_cache: Dict[Tuple[float, float], str] = {}

    def extract_exif(self, image_path: str) -> Dict[str, any]:
        """
        æå–å›¾ç‰‡ EXIF å…ƒæ•°æ®

        Args:
            image_path: å›¾ç‰‡æ–‡ä»¶è·¯å¾„

        Returns:
            dict: EXIF æ•°æ®å­—å…¸
            {
                'make': 'Canon',
                'model': 'EOS R5',
                'datetime': '2026:02:14 14:30:00',
                'iso': 400,
                'aperture': 2.8,
                'shutter_speed': '1/1000',
                'focal_length': 50.0,
                'gps_lat': 39.9042,
                'gps_lng': 116.4074
            }

        Raises:
            FileNotFoundError: æ–‡ä»¶ä¸å­˜åœ¨
            ValueError: æ–‡ä»¶ä¸æ˜¯æœ‰æ•ˆå›¾ç‰‡
        """
        if not Path(image_path).exists():
            raise FileNotFoundError(f"å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {image_path}")

        try:
            img = Image.open(image_path)
            exif_data = img.getexif()

            if not exif_data:
                logger.debug(f"å›¾ç‰‡æ—  EXIF æ•°æ®: {image_path}")
                return {}

            # æå–åŸºç¡€ä¿¡æ¯
            result = {
                'make': self._get_exif_tag(exif_data, 'Make'),
                'model': self._get_exif_tag(exif_data, 'Model'),
                'datetime': self._get_exif_tag(exif_data, 'DateTimeOriginal'),
                'iso': self._get_exif_tag(exif_data, 'ISOSpeedRatings'),
                'aperture': self._parse_aperture(exif_data),
                'shutter_speed': self._parse_shutter_speed(exif_data),
                'focal_length': self._parse_focal_length(exif_data),
            }

            # æå– GPS ä¿¡æ¯
            gps_info = self._extract_gps(exif_data)
            if gps_info:
                result['gps_lat'] = gps_info['latitude']
                result['gps_lng'] = gps_info['longitude']

            # æ¸…ç† None å€¼
            result = {k: v for k, v in result.items() if v is not None}

            return result

        except Exception as e:
            logger.error(f"æå– EXIF å¤±è´¥: {image_path}, é”™è¯¯: {e}")
            return {}

    def _get_exif_tag(self, exif_data, tag_name: str) -> Optional[any]:
        """è·å– EXIF æ ‡ç­¾å€¼"""
        for tag_id, value in exif_data.items():
            if TAGS.get(tag_id) == tag_name:
                return value
        return None

    def _parse_aperture(self, exif_data) -> Optional[float]:
        """
        è§£æå…‰åœˆå€¼

        EXIF FNumber æ ¼å¼ï¼š(280, 100) è¡¨ç¤º f/2.8
        """
        f_number = self._get_exif_tag(exif_data, 'FNumber')
        if f_number and isinstance(f_number, tuple) and len(f_number) == 2:
            return round(f_number[0] / f_number[1], 1)
        return None

    def _parse_shutter_speed(self, exif_data) -> Optional[str]:
        """
        è§£æå¿«é—¨é€Ÿåº¦

        EXIF ExposureTime æ ¼å¼ï¼š(1, 1000) è¡¨ç¤º 1/1000s
        """
        exposure_time = self._get_exif_tag(exif_data, 'ExposureTime')
        if exposure_time and isinstance(exposure_time, tuple) and len(exposure_time) == 2:
            numerator, denominator = exposure_time
            if numerator == 1:
                return f"1/{denominator}"
            else:
                return f"{numerator}/{denominator}"
        return None

    def _parse_focal_length(self, exif_data) -> Optional[float]:
        """
        è§£æç„¦è·

        EXIF FocalLength æ ¼å¼ï¼š(500, 10) è¡¨ç¤º 50.0mm
        """
        focal_length = self._get_exif_tag(exif_data, 'FocalLength')
        if focal_length and isinstance(focal_length, tuple) and len(focal_length) == 2:
            return round(focal_length[0] / focal_length[1], 1)
        return None

    def _extract_gps(self, exif_data) -> Optional[Dict[str, float]]:
        """
        æå– GPS åæ ‡

        Returns:
            dict: {'latitude': 39.9042, 'longitude': 116.4074}
        """
        gps_info = self._get_exif_tag(exif_data, 'GPSInfo')
        if not gps_info:
            return None

        try:
            # è§£æçº¬åº¦
            lat = self._parse_gps_coordinate(
                gps_info.get(2),  # GPSLatitude
                gps_info.get(1)   # GPSLatitudeRef (N/S)
            )

            # è§£æç»åº¦
            lng = self._parse_gps_coordinate(
                gps_info.get(4),  # GPSLongitude
                gps_info.get(3)   # GPSLongitudeRef (E/W)
            )

            if lat is not None and lng is not None:
                return {'latitude': lat, 'longitude': lng}

        except Exception as e:
            logger.warning(f"è§£æ GPS å¤±è´¥: {e}")

        return None

    def _parse_gps_coordinate(self, coord, ref) -> Optional[float]:
        """
        è§£æ GPS åæ ‡

        Args:
            coord: ((åº¦, 1), (åˆ†, 1), (ç§’, 100))
            ref: 'N'/'S'/'E'/'W'

        Returns:
            float: åè¿›åˆ¶åæ ‡
        """
        if not coord or not ref:
            return None

        try:
            degrees = coord[0][0] / coord[0][1]
            minutes = coord[1][0] / coord[1][1]
            seconds = coord[2][0] / coord[2][1]

            decimal = degrees + (minutes / 60.0) + (seconds / 3600.0)

            # å—çº¬å’Œè¥¿ç»ä¸ºè´Ÿå€¼
            if ref in ['S', 'W']:
                decimal = -decimal

            return round(decimal, 6)

        except Exception as e:
            logger.warning(f"è§£æåæ ‡å¤±è´¥: {e}")
            return None

    def reverse_geocode(
        self,
        latitude: float,
        longitude: float,
        language: str = 'zh-CN'
    ) -> Optional[str]:
        """
        GPS åæ ‡åæŸ¥åœ°ç†ä½ç½®

        Args:
            latitude: çº¬åº¦
            longitude: ç»åº¦
            language: è¯­è¨€ï¼ˆé»˜è®¤ä¸­æ–‡ï¼‰

        Returns:
            str: åœ°ç†ä½ç½®ï¼ˆä¾‹å¦‚ï¼šåŒ—äº¬å¸‚æœé˜³åŒºï¼‰
            None: æŸ¥è¯¢å¤±è´¥

        ç¤ºä¾‹ï¼š
            >>> analyzer.reverse_geocode(39.9042, 116.4074)
            'åŒ—äº¬å¸‚æœé˜³åŒº'
        """
        # æ£€æŸ¥ç¼“å­˜
        cache_key = (round(latitude, 4), round(longitude, 4))
        if cache_key in self._location_cache:
            return self._location_cache[cache_key]

        try:
            location = self.geolocator.reverse(
                f"{latitude}, {longitude}",
                language=language,
                timeout=10
            )

            if location and location.address:
                # æå–ç®€åŒ–åœ°å€ï¼ˆåŸå¸‚ + åŒºï¼‰
                address = self._simplify_address(location.address)
                self._location_cache[cache_key] = address
                return address

        except GeocoderTimedOut:
            logger.warning(f"GPS åæŸ¥è¶…æ—¶: ({latitude}, {longitude})")
        except GeocoderServiceError as e:
            logger.warning(f"GPS åæŸ¥å¤±è´¥: {e}")
        except Exception as e:
            logger.error(f"GPS åæŸ¥å¼‚å¸¸: {e}")

        return None

    def _simplify_address(self, full_address: str) -> str:
        """
        ç®€åŒ–åœ°å€ï¼ˆæå–åŸå¸‚ + åŒºï¼‰

        Args:
            full_address: "æœé˜³åŒº, åŒ—äº¬å¸‚, 100000, ä¸­å›½"

        Returns:
            str: "åŒ—äº¬å¸‚æœé˜³åŒº"
        """
        # ç®€å•å¤„ç†ï¼šæå–å‰ä¸¤ä¸ªé€—å·åˆ†éš”çš„éƒ¨åˆ†
        parts = full_address.split(',')
        if len(parts) >= 2:
            return f"{parts[1].strip()}{parts[0].strip()}"
        return full_address

    def get_camera_stats(self) -> List[Dict]:
        """
        è·å–ç›¸æœºä½¿ç”¨ç»Ÿè®¡

        Returns:
            list: ç›¸æœºç»Ÿè®¡åˆ—è¡¨
            [
                {
                    'make': 'Canon',
                    'model': 'EOS R5',
                    'photo_count': 120,
                    'post_count': 15
                },
                ...
            ]
        """
        if not self.db:
            raise ValueError("éœ€è¦æ•°æ®åº“è¿æ¥")

        conn = self.db.get_connection()
        cursor = conn.execute("""
            SELECT
                exif_make as make,
                exif_model as model,
                COUNT(*) as photo_count,
                COUNT(DISTINCT post_id) as post_count
            FROM media
            WHERE media_type = 'image'
              AND exif_make IS NOT NULL
              AND exif_model IS NOT NULL
            GROUP BY exif_make, exif_model
            ORDER BY photo_count DESC
            LIMIT 10
        """)

        return [dict(row) for row in cursor.fetchall()]

    def get_shooting_params_distribution(self) -> Dict[str, Dict]:
        """
        è·å–æ‹æ‘„å‚æ•°åˆ†å¸ƒ

        Returns:
            dict: å‚æ•°åˆ†å¸ƒç»Ÿè®¡
            {
                'iso': {100: 20, 400: 35, 800: 15, ...},
                'aperture': {1.8: 10, 2.8: 25, 5.6: 30, ...},
                'focal_length': {24: 15, 50: 40, 85: 20, ...}
            }
        """
        if not self.db:
            raise ValueError("éœ€è¦æ•°æ®åº“è¿æ¥")

        conn = self.db.get_connection()

        # ISO åˆ†å¸ƒ
        cursor = conn.execute("""
            SELECT exif_iso, COUNT(*) as count
            FROM media
            WHERE exif_iso IS NOT NULL
            GROUP BY exif_iso
            ORDER BY exif_iso
        """)
        iso_dist = {row[0]: row[1] for row in cursor.fetchall()}

        # å…‰åœˆåˆ†å¸ƒ
        cursor = conn.execute("""
            SELECT exif_aperture, COUNT(*) as count
            FROM media
            WHERE exif_aperture IS NOT NULL
            GROUP BY exif_aperture
            ORDER BY exif_aperture
        """)
        aperture_dist = {row[0]: row[1] for row in cursor.fetchall()}

        # ç„¦è·åˆ†å¸ƒ
        cursor = conn.execute("""
            SELECT exif_focal_length, COUNT(*) as count
            FROM media
            WHERE exif_focal_length IS NOT NULL
            GROUP BY exif_focal_length
            ORDER BY exif_focal_length
        """)
        focal_length_dist = {row[0]: row[1] for row in cursor.fetchall()}

        return {
            'iso': iso_dist,
            'aperture': aperture_dist,
            'focal_length': focal_length_dist
        }

    def batch_extract_exif(
        self,
        media_records: List[Dict],
        show_progress: bool = True
    ) -> Dict[str, int]:
        """
        æ‰¹é‡æå– EXIF æ•°æ®

        Args:
            media_records: Media è®°å½•åˆ—è¡¨
                [{'media_id': 1, 'file_path': '/path/to/img.jpg'}, ...]
            show_progress: æ˜¯å¦æ˜¾ç¤ºè¿›åº¦æ¡

        Returns:
            dict: ç»Ÿè®¡ç»“æœ
            {
                'total': 100,
                'success': 85,
                'failed': 15,
                'has_gps': 20
            }
        """
        from rich.progress import Progress, TaskID

        total = len(media_records)
        success = 0
        failed = 0
        has_gps = 0

        if show_progress:
            with Progress() as progress:
                task = progress.add_task(
                    "[cyan]æå– EXIF æ•°æ®...",
                    total=total
                )

                for record in media_records:
                    self._process_single_media(record)
                    progress.update(task, advance=1)
        else:
            for record in media_records:
                result = self._process_single_media(record)
                if result:
                    success += 1
                    if result.get('gps_lat'):
                        has_gps += 1
                else:
                    failed += 1

        return {
            'total': total,
            'success': success,
            'failed': failed,
            'has_gps': has_gps
        }

    def _process_single_media(self, record: Dict) -> Optional[Dict]:
        """å¤„ç†å•ä¸ª Media è®°å½•"""
        try:
            exif_data = self.extract_exif(record['file_path'])

            if exif_data:
                # GPS åæŸ¥ï¼ˆå¦‚æœæœ‰åæ ‡ï¼‰
                if 'gps_lat' in exif_data and 'gps_lng' in exif_data:
                    location = self.reverse_geocode(
                        exif_data['gps_lat'],
                        exif_data['gps_lng']
                    )
                    if location:
                        exif_data['location'] = location

                # æ›´æ–°æ•°æ®åº“
                if self.db:
                    self._update_media_exif(record['media_id'], exif_data)

                return exif_data

        except Exception as e:
            logger.error(f"å¤„ç†å¤±è´¥: {record['file_path']}, é”™è¯¯: {e}")

        return None

    def _update_media_exif(self, media_id: int, exif_data: Dict):
        """æ›´æ–° Media è¡¨çš„ EXIF å­—æ®µ"""
        if not self.db:
            return

        conn = self.db.get_connection()

        # æ„å»º UPDATE è¯­å¥
        fields = []
        values = []

        field_mapping = {
            'make': 'exif_make',
            'model': 'exif_model',
            'datetime': 'exif_datetime',
            'iso': 'exif_iso',
            'aperture': 'exif_aperture',
            'shutter_speed': 'exif_shutter_speed',
            'focal_length': 'exif_focal_length',
            'gps_lat': 'exif_gps_lat',
            'gps_lng': 'exif_gps_lng',
            'location': 'exif_location'
        }

        for key, db_field in field_mapping.items():
            if key in exif_data:
                fields.append(f"{db_field} = ?")
                values.append(exif_data[key])

        if fields:
            values.append(media_id)
            sql = f"UPDATE media SET {', '.join(fields)} WHERE media_id = ?"
            conn.execute(sql, values)
            conn.commit()
```

#### 3.1.2 ä½¿ç”¨ç¤ºä¾‹

```python
from database import get_default_connection
from analysis import ExifAnalyzer

# åˆå§‹åŒ–
db = get_default_connection()
analyzer = ExifAnalyzer(db)

# å•å¼ å›¾ç‰‡ EXIF æå–
exif = analyzer.extract_exif('/path/to/photo.jpg')
print(exif)
# {'make': 'Canon', 'model': 'EOS R5', 'iso': 400, ...}

# GPS åæŸ¥
location = analyzer.reverse_geocode(39.9042, 116.4074)
print(location)  # "åŒ—äº¬å¸‚æœé˜³åŒº"

# ç›¸æœºç»Ÿè®¡
stats = analyzer.get_camera_stats()
print(stats)
# [{'make': 'Canon', 'model': 'EOS R5', 'photo_count': 120}, ...]

# æ‰¹é‡æå–ï¼ˆå†å²æ•°æ®è¿ç§»ï¼‰
from database import Media
media_list = Media.get_all_images_without_exif()
result = analyzer.batch_extract_exif(media_list, show_progress=True)
print(result)
# {'total': 1000, 'success': 950, 'failed': 50, 'has_gps': 200}
```

#### 3.1.3 æµ‹è¯•ç”¨ä¾‹

**æ–‡ä»¶**: `test_exif_analyzer.py`

```python
import pytest
from analysis.exif_analyzer import ExifAnalyzer

def test_extract_exif_basic():
    """æµ‹è¯•åŸºç¡€ EXIF æå–"""
    analyzer = ExifAnalyzer()
    exif = analyzer.extract_exif('test_data/photo_with_exif.jpg')

    assert 'make' in exif
    assert 'model' in exif
    assert isinstance(exif.get('iso'), int)

def test_extract_exif_no_exif():
    """æµ‹è¯•æ—  EXIF æ•°æ®çš„å›¾ç‰‡"""
    analyzer = ExifAnalyzer()
    exif = analyzer.extract_exif('test_data/photo_no_exif.jpg')

    assert exif == {}

def test_extract_gps():
    """æµ‹è¯• GPS æå–"""
    analyzer = ExifAnalyzer()
    exif = analyzer.extract_exif('test_data/photo_with_gps.jpg')

    assert 'gps_lat' in exif
    assert 'gps_lng' in exif
    assert -90 <= exif['gps_lat'] <= 90
    assert -180 <= exif['gps_lng'] <= 180

def test_reverse_geocode():
    """æµ‹è¯• GPS åæŸ¥"""
    analyzer = ExifAnalyzer()
    location = analyzer.reverse_geocode(39.9042, 116.4074)

    assert location is not None
    assert 'åŒ—äº¬' in location

def test_parse_aperture():
    """æµ‹è¯•å…‰åœˆè§£æ"""
    # å®ç°ç»†èŠ‚æµ‹è¯•
    pass

def test_camera_stats():
    """æµ‹è¯•ç›¸æœºç»Ÿè®¡"""
    # éœ€è¦æ•°æ®åº“è¿æ¥
    pass
```

---

### 3.2 æ–‡æœ¬åˆ†æå™¨ï¼ˆtext_analyzer.pyï¼‰

#### 3.2.1 æ ¸å¿ƒç±»è®¾è®¡

```python
"""
æ–‡æœ¬åˆ†æå™¨æ¨¡å—

åŠŸèƒ½ï¼š
1. ä¸­æ–‡åˆ†è¯ï¼ˆjiebaï¼‰
2. è¯é¢‘ç»Ÿè®¡
3. è¯äº‘ç”Ÿæˆ
4. å…³é”®è¯æå–ï¼ˆå¯é€‰ï¼‰

ä¾èµ–ï¼š
- jieba
- wordcloud
- matplotlib

ä½œè€…: Claude Sonnet 4.5
æ—¥æœŸ: 2026-02-14
"""

from typing import List, Dict, Optional
from pathlib import Path
import jieba
from wordcloud import WordCloud
import matplotlib.pyplot as plt
import logging

logger = logging.getLogger(__name__)


class TextAnalyzer:
    """æ–‡æœ¬åˆ†æå™¨"""

    def __init__(self, db_connection=None, stopwords_path: str = None):
        """
        åˆå§‹åŒ–æ–‡æœ¬åˆ†æå™¨

        Args:
            db_connection: æ•°æ®åº“è¿æ¥ï¼ˆå¯é€‰ï¼‰
            stopwords_path: åœç”¨è¯è¡¨è·¯å¾„ï¼ˆå¯é€‰ï¼‰
        """
        self.db = db_connection

        # åŠ è½½åœç”¨è¯
        if stopwords_path and Path(stopwords_path).exists():
            self.stopwords = self._load_stopwords(stopwords_path)
        else:
            self.stopwords = self._default_stopwords()

        # é…ç½® jieba
        jieba.setLogLevel(logging.INFO)

    def _load_stopwords(self, path: str) -> set:
        """åŠ è½½åœç”¨è¯è¡¨"""
        with open(path, 'r', encoding='utf-8') as f:
            return set(line.strip() for line in f if line.strip())

    def _default_stopwords(self) -> set:
        """é»˜è®¤åœç”¨è¯"""
        return {
            'çš„', 'äº†', 'åœ¨', 'æ˜¯', 'æˆ‘', 'æœ‰', 'å’Œ', 'å°±', 'ä¸', 'äºº',
            'éƒ½', 'ä¸€', 'ä¸€ä¸ª', 'ä¸Š', 'ä¹Ÿ', 'å¾ˆ', 'åˆ°', 'è¯´', 'è¦', 'å»',
            'ä½ ', 'ä¼š', 'ç€', 'æ²¡æœ‰', 'çœ‹', 'å¥½', 'è‡ªå·±', 'è¿™', 'ä¸ª', 'ä»¬'
        }

    def segment(self, text: str, min_length: int = 2) -> List[str]:
        """
        ä¸­æ–‡åˆ†è¯

        Args:
            text: å¾…åˆ†è¯æ–‡æœ¬
            min_length: æœ€å°è¯é•¿ï¼ˆé»˜è®¤ 2ï¼‰

        Returns:
            list: åˆ†è¯ç»“æœ
        """
        words = jieba.cut(text)
        words_filtered = [
            w for w in words
            if len(w) >= min_length and w not in self.stopwords
        ]
        return words_filtered

    def calculate_word_freq(
        self,
        text: str,
        top_n: int = 100
    ) -> Dict[str, int]:
        """
        è®¡ç®—è¯é¢‘

        Args:
            text: æ–‡æœ¬
            top_n: è¿”å› Top N ä¸ªè¯

        Returns:
            dict: è¯é¢‘å­—å…¸ {'è¯': é¢‘æ¬¡}
        """
        words = self.segment(text)

        # ç»Ÿè®¡è¯é¢‘
        freq = {}
        for word in words:
            freq[word] = freq.get(word, 0) + 1

        # æ’åºå¹¶å– Top N
        sorted_freq = sorted(
            freq.items(),
            key=lambda x: x[1],
            reverse=True
        )[:top_n]

        return dict(sorted_freq)

    def generate_wordcloud(
        self,
        text: str = None,
        author_name: str = None,
        output_path: str = None,
        width: int = 1920,
        height: int = 1080,
        background_color: str = 'white',
        font_path: str = None
    ) -> str:
        """
        ç”Ÿæˆè¯äº‘å›¾

        Args:
            text: æ–‡æœ¬ï¼ˆä¸ author_name äºŒé€‰ä¸€ï¼‰
            author_name: ä½œè€…åï¼ˆä»æ•°æ®åº“è¯»å–æ‰€æœ‰å¸–å­æ ‡é¢˜ï¼‰
            output_path: è¾“å‡ºè·¯å¾„ï¼ˆé»˜è®¤ï¼šåˆ†ææŠ¥å‘Š/wordcloud/ä½œè€…_wordcloud.pngï¼‰
            width: å®½åº¦ï¼ˆé»˜è®¤ 1920ï¼‰
            height: é«˜åº¦ï¼ˆé»˜è®¤ 1080ï¼‰
            background_color: èƒŒæ™¯è‰²ï¼ˆé»˜è®¤ç™½è‰²ï¼‰
            font_path: å­—ä½“è·¯å¾„ï¼ˆé»˜è®¤è‡ªåŠ¨æ£€æµ‹ï¼‰

        Returns:
            str: è¾“å‡ºæ–‡ä»¶è·¯å¾„

        Raises:
            ValueError: text å’Œ author_name éƒ½æœªæä¾›
        """
        # è·å–æ–‡æœ¬
        if text is None and author_name is None:
            raise ValueError("å¿…é¡»æä¾› text æˆ– author_name")

        if text is None:
            text = self._get_author_text(author_name)

        # åˆ†è¯
        words = self.segment(text)
        words_joined = ' '.join(words)

        # è‡ªåŠ¨æ£€æµ‹å­—ä½“
        if font_path is None:
            font_path = self._detect_chinese_font()

        # ç”Ÿæˆè¯äº‘
        wordcloud = WordCloud(
            font_path=font_path,
            width=width,
            height=height,
            background_color=background_color,
            max_words=200,
            relative_scaling=0.5,
            colormap='viridis'
        ).generate(words_joined)

        # ä¿å­˜æ–‡ä»¶
        if output_path is None:
            name = author_name if author_name else 'å…¨å±€'
            output_path = f"åˆ†ææŠ¥å‘Š/wordcloud/{name}_wordcloud.png"

        Path(output_path).parent.mkdir(parents=True, exist_ok=True)

        plt.figure(figsize=(width/100, height/100), dpi=100)
        plt.imshow(wordcloud, interpolation='bilinear')
        plt.axis('off')
        plt.tight_layout(pad=0)
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        plt.close()

        logger.info(f"è¯äº‘å·²ç”Ÿæˆ: {output_path}")
        return output_path

    def _get_author_text(self, author_name: str) -> str:
        """ä»æ•°æ®åº“è·å–ä½œè€…æ‰€æœ‰å¸–å­æ ‡é¢˜"""
        if not self.db:
            raise ValueError("éœ€è¦æ•°æ®åº“è¿æ¥")

        from database import Post
        posts = Post.get_by_author_name(author_name)

        # åˆå¹¶æ‰€æœ‰æ ‡é¢˜
        titles = [post.title for post in posts if post.title]
        return ' '.join(titles)

    def _detect_chinese_font(self) -> str:
        """è‡ªåŠ¨æ£€æµ‹ä¸­æ–‡å­—ä½“"""
        import platform
        import os

        system = platform.system()

        # Linux
        if system == 'Linux':
            fonts = [
                '/usr/share/fonts/truetype/wqy/wqy-zenhei.ttc',
                '/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc',
            ]
            for font in fonts:
                if os.path.exists(font):
                    return font

        # macOS
        elif system == 'Darwin':
            return '/System/Library/Fonts/PingFang.ttc'

        # Windows
        elif system == 'Windows':
            return 'C:/Windows/Fonts/msyh.ttc'

        # é»˜è®¤ï¼ˆå¯èƒ½å¤±è´¥ï¼‰
        logger.warning("æœªæ‰¾åˆ°ä¸­æ–‡å­—ä½“ï¼Œå¯èƒ½å‡ºç°ä¹±ç ")
        return None

    def generate_multi_author_wordcloud(
        self,
        author_names: List[str],
        output_dir: str = "åˆ†ææŠ¥å‘Š/wordcloud/"
    ) -> List[str]:
        """
        æ‰¹é‡ç”Ÿæˆå¤šä¸ªä½œè€…çš„è¯äº‘

        Args:
            author_names: ä½œè€…ååˆ—è¡¨
            output_dir: è¾“å‡ºç›®å½•

        Returns:
            list: ç”Ÿæˆçš„æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        """
        output_paths = []

        for author_name in author_names:
            try:
                output_path = f"{output_dir}/{author_name}_wordcloud.png"
                path = self.generate_wordcloud(
                    author_name=author_name,
                    output_path=output_path
                )
                output_paths.append(path)
            except Exception as e:
                logger.error(f"ç”Ÿæˆè¯äº‘å¤±è´¥: {author_name}, é”™è¯¯: {e}")

        return output_paths

    def extract_keywords(
        self,
        text: str,
        top_n: int = 10,
        method: str = 'tfidf'
    ) -> List[tuple]:
        """
        æå–å…³é”®è¯ï¼ˆå¯é€‰åŠŸèƒ½ï¼‰

        Args:
            text: æ–‡æœ¬
            top_n: è¿”å› Top N ä¸ªå…³é”®è¯
            method: æå–æ–¹æ³•ï¼ˆ'tfidf' æˆ– 'textrank'ï¼‰

        Returns:
            list: [(å…³é”®è¯, æƒé‡), ...]
        """
        import jieba.analyse

        if method == 'tfidf':
            keywords = jieba.analyse.extract_tags(
                text,
                topK=top_n,
                withWeight=True
            )
        elif method == 'textrank':
            keywords = jieba.analyse.textrank(
                text,
                topK=top_n,
                withWeight=True
            )
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ–¹æ³•: {method}")

        return keywords
```

#### 3.2.2 ä½¿ç”¨ç¤ºä¾‹

```python
from database import get_default_connection
from analysis import TextAnalyzer

# åˆå§‹åŒ–
db = get_default_connection()
analyzer = TextAnalyzer(db, stopwords_path='python/src/utils/stopwords.txt')

# å•ä¸ªä½œè€…è¯äº‘
wordcloud_path = analyzer.generate_wordcloud(author_name="ç‹¬é†‰ç¬‘æ¸…é£")
print(f"è¯äº‘å·²ç”Ÿæˆ: {wordcloud_path}")

# æ‰¹é‡ç”Ÿæˆ
authors = ['ç‹¬é†‰ç¬‘æ¸…é£', 'æ¸…é£çš“æœˆ', 'åŒèŠ±é¡ºå¿ƒ']
paths = analyzer.generate_multi_author_wordcloud(authors)

# å…¨å±€è¯äº‘ï¼ˆæ‰€æœ‰ä½œè€…ï¼‰
all_text = "ä»æ•°æ®åº“è·å–æ‰€æœ‰æ ‡é¢˜..."
analyzer.generate_wordcloud(text=all_text, output_path="å…¨å±€_wordcloud.png")

# è¯é¢‘ç»Ÿè®¡
freq = analyzer.calculate_word_freq(all_text, top_n=20)
print(freq)
# {'ç¾å¥³': 120, 'æ€§æ„Ÿ': 95, 'è¯±æƒ‘': 80, ...}

# å…³é”®è¯æå–
keywords = analyzer.extract_keywords(all_text, top_n=10)
print(keywords)
# [('ç¾å¥³', 0.85), ('æ€§æ„Ÿ', 0.72), ...]
```

---

### 3.3 æ—¶é—´åˆ†æå™¨ï¼ˆtime_analyzer.pyï¼‰

#### 3.3.1 æ ¸å¿ƒç±»è®¾è®¡

```python
"""
æ—¶é—´åˆ†æå™¨æ¨¡å—

åŠŸèƒ½ï¼š
1. æœˆåº¦è¶‹åŠ¿åˆ†æ
2. æ—¶é—´çƒ­åŠ›å›¾ï¼ˆå°æ—¶ x æ˜ŸæœŸï¼‰
3. æ´»è·ƒåº¦åˆ†æ

ä¾èµ–ï¼š
- matplotlib
- seaborn
- pandas

ä½œè€…: Claude Sonnet 4.5
æ—¥æœŸ: 2026-02-14
"""

from typing import Dict, List, Optional
from pathlib import Path
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import logging

logger = logging.getLogger(__name__)


class TimeAnalyzer:
    """æ—¶é—´åˆ†æå™¨"""

    def __init__(self, db_connection=None, font_config=None):
        """
        åˆå§‹åŒ–æ—¶é—´åˆ†æå™¨

        Args:
            db_connection: æ•°æ®åº“è¿æ¥
            font_config: å­—ä½“é…ç½®ï¼ˆFontConfig å®ä¾‹ï¼‰
        """
        self.db = db_connection

        # é…ç½®ä¸­æ–‡å­—ä½“
        if font_config:
            font_config.setup_matplotlib_font()
        else:
            self._setup_default_font()

    def _setup_default_font(self):
        """é…ç½®é»˜è®¤ä¸­æ–‡å­—ä½“"""
        import matplotlib
        matplotlib.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']
        matplotlib.rcParams['axes.unicode_minus'] = False

    def get_monthly_trend(
        self,
        author_name: str = None
    ) -> pd.DataFrame:
        """
        è·å–æœˆåº¦è¶‹åŠ¿æ•°æ®

        Args:
            author_name: ä½œè€…åï¼ˆNone è¡¨ç¤ºå…¨å±€ï¼‰

        Returns:
            DataFrame: æœˆåº¦æ•°æ®
            columns: ['year_month', 'post_count', 'image_count', 'video_count']
        """
        if not self.db:
            raise ValueError("éœ€è¦æ•°æ®åº“è¿æ¥")

        conn = self.db.get_connection()

        if author_name:
            sql = """
                SELECT
                    publish_year || '-' || printf('%02d', publish_month) as year_month,
                    COUNT(*) as post_count,
                    SUM(image_count) as image_count,
                    SUM(video_count) as video_count
                FROM posts
                WHERE author_id = (SELECT author_id FROM authors WHERE name = ?)
                  AND publish_year IS NOT NULL
                  AND publish_month IS NOT NULL
                GROUP BY publish_year, publish_month
                ORDER BY publish_year, publish_month
            """
            df = pd.read_sql_query(sql, conn, params=(author_name,))
        else:
            sql = """
                SELECT
                    publish_year || '-' || printf('%02d', publish_month) as year_month,
                    COUNT(*) as post_count,
                    SUM(image_count) as image_count,
                    SUM(video_count) as video_count
                FROM posts
                WHERE publish_year IS NOT NULL
                  AND publish_month IS NOT NULL
                GROUP BY publish_year, publish_month
                ORDER BY publish_year, publish_month
            """
            df = pd.read_sql_query(sql, conn)

        return df

    def plot_monthly_trend(
        self,
        author_name: str = None,
        output_path: str = None,
        figsize: tuple = (14, 6),
        dpi: int = 300
    ) -> str:
        """
        ç»˜åˆ¶æœˆåº¦è¶‹åŠ¿å›¾

        Args:
            author_name: ä½œè€…å
            output_path: è¾“å‡ºè·¯å¾„
            figsize: å›¾è¡¨å¤§å°
            dpi: åˆ†è¾¨ç‡

        Returns:
            str: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        df = self.get_monthly_trend(author_name)

        if df.empty:
            logger.warning("æ— æ•°æ®ï¼Œæ— æ³•ç”Ÿæˆè¶‹åŠ¿å›¾")
            return None

        # ç»˜å›¾
        fig, ax = plt.subplots(figsize=figsize)

        ax.plot(
            df['year_month'],
            df['post_count'],
            marker='o',
            linewidth=2,
            markersize=6,
            label='å¸–å­æ•°'
        )

        # æ ‡é¢˜
        title = f"{author_name} å‘å¸–æœˆåº¦è¶‹åŠ¿" if author_name else "å…¨å±€å‘å¸–æœˆåº¦è¶‹åŠ¿"
        ax.set_title(title, fontsize=16, fontweight='bold', pad=20)

        ax.set_xlabel('æœˆä»½', fontsize=12)
        ax.set_ylabel('å¸–å­æ•°', fontsize=12)

        # æ—‹è½¬ x è½´æ ‡ç­¾
        plt.xticks(rotation=45, ha='right')

        # ç½‘æ ¼
        ax.grid(True, alpha=0.3, linestyle='--')

        # å›¾ä¾‹
        ax.legend(fontsize=10)

        plt.tight_layout()

        # ä¿å­˜
        if output_path is None:
            name = author_name if author_name else 'å…¨å±€'
            output_path = f"åˆ†ææŠ¥å‘Š/charts/{name}_monthly_trend.png"

        Path(output_path).parent.mkdir(parents=True, exist_ok=True)
        plt.savefig(output_path, dpi=dpi, bbox_inches='tight')
        plt.close()

        logger.info(f"æœˆåº¦è¶‹åŠ¿å›¾å·²ç”Ÿæˆ: {output_path}")
        return output_path

    def get_time_heatmap_data(
        self,
        author_name: str = None
    ) -> pd.DataFrame:
        """
        è·å–æ—¶é—´çƒ­åŠ›å›¾æ•°æ®

        Args:
            author_name: ä½œè€…å

        Returns:
            DataFrame: çƒ­åŠ›å›¾æ•°æ®
            index: weekday (0-6)
            columns: hour (0-23)
            values: post_count
        """
        if not self.db:
            raise ValueError("éœ€è¦æ•°æ®åº“è¿æ¥")

        conn = self.db.get_connection()

        if author_name:
            sql = """
                SELECT
                    publish_weekday,
                    publish_hour,
                    COUNT(*) as post_count
                FROM posts
                WHERE author_id = (SELECT author_id FROM authors WHERE name = ?)
                  AND publish_weekday IS NOT NULL
                  AND publish_hour IS NOT NULL
                GROUP BY publish_weekday, publish_hour
            """
            df = pd.read_sql_query(sql, conn, params=(author_name,))
        else:
            sql = """
                SELECT
                    publish_weekday,
                    publish_hour,
                    COUNT(*) as post_count
                FROM posts
                WHERE publish_weekday IS NOT NULL
                  AND publish_hour IS NOT NULL
                GROUP BY publish_weekday, publish_hour
            """
            df = pd.read_sql_query(sql, conn)

        # è½¬æ¢ä¸º pivot è¡¨
        pivot = df.pivot(
            index='publish_weekday',
            columns='publish_hour',
            values='post_count'
        ).fillna(0)

        return pivot

    def plot_time_heatmap(
        self,
        author_name: str = None,
        output_path: str = None,
        figsize: tuple = (16, 8),
        dpi: int = 300
    ) -> str:
        """
        ç»˜åˆ¶æ—¶é—´çƒ­åŠ›å›¾

        Args:
            author_name: ä½œè€…å
            output_path: è¾“å‡ºè·¯å¾„
            figsize: å›¾è¡¨å¤§å°
            dpi: åˆ†è¾¨ç‡

        Returns:
            str: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        pivot = self.get_time_heatmap_data(author_name)

        if pivot.empty:
            logger.warning("æ— æ•°æ®ï¼Œæ— æ³•ç”Ÿæˆçƒ­åŠ›å›¾")
            return None

        # ç»˜å›¾
        fig, ax = plt.subplots(figsize=figsize)

        # æ˜ŸæœŸæ ‡ç­¾
        weekday_labels = ['å‘¨ä¸€', 'å‘¨äºŒ', 'å‘¨ä¸‰', 'å‘¨å››', 'å‘¨äº”', 'å‘¨å…­', 'å‘¨æ—¥']

        sns.heatmap(
            pivot,
            cmap='YlOrRd',
            annot=True,
            fmt='.0f',
            linewidths=0.5,
            cbar_kws={'label': 'å¸–å­æ•°'},
            yticklabels=weekday_labels,
            ax=ax
        )

        # æ ‡é¢˜
        title = f"{author_name} å‘å¸–æ—¶é—´çƒ­åŠ›å›¾" if author_name else "å…¨å±€å‘å¸–æ—¶é—´çƒ­åŠ›å›¾"
        ax.set_title(title, fontsize=16, fontweight='bold', pad=20)

        ax.set_xlabel('å°æ—¶', fontsize=12)
        ax.set_ylabel('æ˜ŸæœŸ', fontsize=12)

        plt.tight_layout()

        # ä¿å­˜
        if output_path is None:
            name = author_name if author_name else 'å…¨å±€'
            output_path = f"åˆ†ææŠ¥å‘Š/charts/{name}_time_heatmap.png"

        Path(output_path).parent.mkdir(parents=True, exist_ok=True)
        plt.savefig(output_path, dpi=dpi, bbox_inches='tight')
        plt.close()

        logger.info(f"æ—¶é—´çƒ­åŠ›å›¾å·²ç”Ÿæˆ: {output_path}")
        return output_path

    def analyze_active_patterns(
        self,
        author_name: str = None
    ) -> Dict:
        """
        åˆ†ææ´»è·ƒæ¨¡å¼

        Args:
            author_name: ä½œè€…å

        Returns:
            dict: æ´»è·ƒæ¨¡å¼åˆ†æ
            {
                'most_active_hour': 14,           # æœ€æ´»è·ƒå°æ—¶
                'most_active_weekday': 2,         # æœ€æ´»è·ƒæ˜ŸæœŸï¼ˆ0=å‘¨ä¸€ï¼‰
                'weekday_vs_weekend': {
                    'weekday': 80,                # å·¥ä½œæ—¥å¸–å­æ•°
                    'weekend': 20                 # å‘¨æœ«å¸–å­æ•°
                },
                'peak_hours': [14, 15, 20],       # é«˜å³°æ—¶æ®µ
                'active_pattern': 'night_owl'     # æ´»è·ƒæ¨¡å¼ï¼šnight_owl/early_bird/balanced
            }
        """
        if not self.db:
            raise ValueError("éœ€è¦æ•°æ®åº“è¿æ¥")

        conn = self.db.get_connection()

        # å°æ—¶åˆ†å¸ƒ
        if author_name:
            cursor = conn.execute("""
                SELECT publish_hour, COUNT(*) as count
                FROM posts
                WHERE author_id = (SELECT author_id FROM authors WHERE name = ?)
                  AND publish_hour IS NOT NULL
                GROUP BY publish_hour
                ORDER BY count DESC
            """, (author_name,))
        else:
            cursor = conn.execute("""
                SELECT publish_hour, COUNT(*) as count
                FROM posts
                WHERE publish_hour IS NOT NULL
                GROUP BY publish_hour
                ORDER BY count DESC
            """)

        hour_dist = {row[0]: row[1] for row in cursor.fetchall()}
        most_active_hour = max(hour_dist, key=hour_dist.get) if hour_dist else None

        # æ˜ŸæœŸåˆ†å¸ƒ
        if author_name:
            cursor = conn.execute("""
                SELECT publish_weekday, COUNT(*) as count
                FROM posts
                WHERE author_id = (SELECT author_id FROM authors WHERE name = ?)
                  AND publish_weekday IS NOT NULL
                GROUP BY publish_weekday
                ORDER BY count DESC
            """, (author_name,))
        else:
            cursor = conn.execute("""
                SELECT publish_weekday, COUNT(*) as count
                FROM posts
                WHERE publish_weekday IS NOT NULL
                GROUP BY publish_weekday
                ORDER BY count DESC
            """)

        weekday_dist = {row[0]: row[1] for row in cursor.fetchall()}
        most_active_weekday = max(weekday_dist, key=weekday_dist.get) if weekday_dist else None

        # å·¥ä½œæ—¥ vs å‘¨æœ«
        weekday_count = sum(weekday_dist.get(i, 0) for i in range(5))  # å‘¨ä¸€åˆ°å‘¨äº”
        weekend_count = sum(weekday_dist.get(i, 0) for i in [5, 6])    # å‘¨å…­ã€å‘¨æ—¥

        # é«˜å³°æ—¶æ®µï¼ˆTop 3 å°æ—¶ï¼‰
        sorted_hours = sorted(hour_dist.items(), key=lambda x: x[1], reverse=True)
        peak_hours = [hour for hour, _ in sorted_hours[:3]]

        # æ´»è·ƒæ¨¡å¼åˆ¤æ–­
        active_pattern = self._determine_active_pattern(most_active_hour)

        return {
            'most_active_hour': most_active_hour,
            'most_active_weekday': most_active_weekday,
            'weekday_vs_weekend': {
                'weekday': weekday_count,
                'weekend': weekend_count
            },
            'peak_hours': peak_hours,
            'active_pattern': active_pattern
        }

    def _determine_active_pattern(self, most_active_hour: int) -> str:
        """åˆ¤æ–­æ´»è·ƒæ¨¡å¼"""
        if most_active_hour is None:
            return 'unknown'

        if 6 <= most_active_hour <= 11:
            return 'early_bird'      # æ—©èµ·é¸Ÿ
        elif 22 <= most_active_hour or most_active_hour <= 2:
            return 'night_owl'       # å¤œçŒ«å­
        else:
            return 'balanced'        # å‡è¡¡å‹
```

#### 3.3.2 ä½¿ç”¨ç¤ºä¾‹

```python
from database import get_default_connection
from analysis import TimeAnalyzer

# åˆå§‹åŒ–
db = get_default_connection()
analyzer = TimeAnalyzer(db)

# æœˆåº¦è¶‹åŠ¿å›¾
trend_path = analyzer.plot_monthly_trend(author_name="ç‹¬é†‰ç¬‘æ¸…é£")
print(f"è¶‹åŠ¿å›¾å·²ç”Ÿæˆ: {trend_path}")

# æ—¶é—´çƒ­åŠ›å›¾
heatmap_path = analyzer.plot_time_heatmap(author_name="ç‹¬é†‰ç¬‘æ¸…é£")
print(f"çƒ­åŠ›å›¾å·²ç”Ÿæˆ: {heatmap_path}")

# æ´»è·ƒåº¦åˆ†æ
patterns = analyzer.analyze_active_patterns(author_name="ç‹¬é†‰ç¬‘æ¸…é£")
print(patterns)
# {
#     'most_active_hour': 14,
#     'most_active_weekday': 2,
#     'weekday_vs_weekend': {'weekday': 80, 'weekend': 20},
#     'peak_hours': [14, 15, 20],
#     'active_pattern': 'balanced'
# }
```

---

ç”±äºæ–‡æ¡£å¤ªé•¿ï¼Œæˆ‘å°†åˆ†æˆä¸¤éƒ¨åˆ†ã€‚è¿™æ˜¯ç¬¬ä¸€éƒ¨åˆ†ï¼ˆEXIF åˆ†æå™¨ + æ–‡æœ¬åˆ†æå™¨ + æ—¶é—´åˆ†æå™¨ï¼‰ã€‚

ç¬¬äºŒéƒ¨åˆ†å°†åŒ…å«ï¼š
- 3.4 å¯è§†åŒ–å™¨
- 3.5 æŠ¥å‘Šç”Ÿæˆå™¨
- 4. æ¥å£è§„èŒƒ
- 5. é…ç½®è®¾è®¡
- 6. æµ‹è¯•è®¾è®¡
- 7. å®æ–½ä»»åŠ¡æ¸…å•
- 8. éªŒæ”¶æ ‡å‡†

æ˜¯å¦ç»§ç»­åˆ›å»ºç¬¬äºŒéƒ¨åˆ†ï¼Ÿ
# Phase 4 è¯¦ç»†è®¾è®¡æ–‡æ¡£ï¼ˆç¬¬äºŒéƒ¨åˆ†ï¼‰

**ç»­æ¥**: PHASE4_DETAILED_DESIGN.md

---

## 3.4 å¯è§†åŒ–å™¨ï¼ˆvisualizer.pyï¼‰

### 3.4.1 æ ¸å¿ƒç±»è®¾è®¡

```python
"""
å¯è§†åŒ–å™¨æ¨¡å—

åŠŸèƒ½ï¼š
1. ç»Ÿä¸€å›¾è¡¨æ ·å¼é…ç½®
2. å„ç±»å›¾è¡¨ç»˜åˆ¶ï¼ˆæŸ±çŠ¶å›¾ã€é¥¼å›¾ã€çƒ­åŠ›å›¾ç­‰ï¼‰
3. ä¸­æ–‡å­—ä½“é…ç½®
4. é«˜æ¸…å›¾ç‰‡è¾“å‡º

ä¾èµ–ï¼š
- matplotlib
- seaborn

ä½œè€…: Claude Sonnet 4.5
æ—¥æœŸ: 2026-02-14
"""

from typing import Dict, List, Optional, Tuple
from pathlib import Path
import matplotlib.pyplot as plt
import seaborn as sns
import logging

logger = logging.getLogger(__name__)


class Visualizer:
    """å¯è§†åŒ–å™¨"""

    def __init__(self, font_config=None, style: str = 'seaborn-v0_8'):
        """
        åˆå§‹åŒ–å¯è§†åŒ–å™¨

        Args:
            font_config: å­—ä½“é…ç½®
            style: matplotlib æ ·å¼
        """
        self.font_config = font_config

        # é…ç½®æ ·å¼
        plt.style.use(style)

        # é…ç½®ä¸­æ–‡å­—ä½“
        if font_config:
            font_config.setup_matplotlib_font()
        else:
            self._setup_default_font()

        # é…ç½®é»˜è®¤å‚æ•°
        self._setup_defaults()

    def _setup_default_font(self):
        """é…ç½®é»˜è®¤ä¸­æ–‡å­—ä½“"""
        import matplotlib
        matplotlib.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']
        matplotlib.rcParams['axes.unicode_minus'] = False

    def _setup_defaults(self):
        """é…ç½®é»˜è®¤å‚æ•°"""
        import matplotlib
        matplotlib.rcParams['figure.dpi'] = 100
        matplotlib.rcParams['savefig.dpi'] = 300
        matplotlib.rcParams['savefig.bbox'] = 'tight'
        matplotlib.rcParams['figure.figsize'] = (12, 6)

    def plot_bar_chart(
        self,
        data: Dict[str, int],
        title: str,
        xlabel: str,
        ylabel: str,
        output_path: str,
        figsize: Tuple[int, int] = (12, 6),
        color: str = '#3498db',
        top_n: int = None
    ) -> str:
        """
        ç»˜åˆ¶æŸ±çŠ¶å›¾

        Args:
            data: æ•°æ®å­—å…¸ {'æ ‡ç­¾': æ•°å€¼}
            title: æ ‡é¢˜
            xlabel: X è½´æ ‡ç­¾
            ylabel: Y è½´æ ‡ç­¾
            output_path: è¾“å‡ºè·¯å¾„
            figsize: å›¾è¡¨å¤§å°
            color: æŸ±å­é¢œè‰²
            top_n: åªæ˜¾ç¤º Top Nï¼ˆå¯é€‰ï¼‰

        Returns:
            str: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        # æ’åºå¹¶å– Top N
        sorted_data = sorted(data.items(), key=lambda x: x[1], reverse=True)
        if top_n:
            sorted_data = sorted_data[:top_n]

        labels, values = zip(*sorted_data)

        # ç»˜å›¾
        fig, ax = plt.subplots(figsize=figsize)

        bars = ax.bar(labels, values, color=color, alpha=0.8)

        # åœ¨æŸ±å­ä¸Šæ˜¾ç¤ºæ•°å€¼
        for bar in bars:
            height = bar.get_height()
            ax.text(
                bar.get_x() + bar.get_width() / 2,
                height,
                f'{int(height)}',
                ha='center',
                va='bottom',
                fontsize=10
            )

        ax.set_title(title, fontsize=16, fontweight='bold', pad=20)
        ax.set_xlabel(xlabel, fontsize=12)
        ax.set_ylabel(ylabel, fontsize=12)

        # æ—‹è½¬ x è½´æ ‡ç­¾
        plt.xticks(rotation=45, ha='right')

        # ç½‘æ ¼
        ax.grid(True, axis='y', alpha=0.3, linestyle='--')

        plt.tight_layout()

        # ä¿å­˜
        Path(output_path).parent.mkdir(parents=True, exist_ok=True)
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        plt.close()

        logger.info(f"æŸ±çŠ¶å›¾å·²ç”Ÿæˆ: {output_path}")
        return output_path

    def plot_pie_chart(
        self,
        data: Dict[str, int],
        title: str,
        output_path: str,
        figsize: Tuple[int, int] = (10, 10),
        colors: List[str] = None,
        explode: List[float] = None
    ) -> str:
        """
        ç»˜åˆ¶é¥¼å›¾

        Args:
            data: æ•°æ®å­—å…¸
            title: æ ‡é¢˜
            output_path: è¾“å‡ºè·¯å¾„
            figsize: å›¾è¡¨å¤§å°
            colors: é¢œè‰²åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰
            explode: çªå‡ºæ˜¾ç¤ºï¼ˆå¯é€‰ï¼‰

        Returns:
            str: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        labels, values = zip(*data.items())

        # é»˜è®¤é¢œè‰²
        if colors is None:
            colors = plt.cm.Set3.colors

        # ç»˜å›¾
        fig, ax = plt.subplots(figsize=figsize)

        wedges, texts, autotexts = ax.pie(
            values,
            labels=labels,
            autopct='%1.1f%%',
            colors=colors,
            explode=explode,
            startangle=90
        )

        # ç¾åŒ–æ–‡æœ¬
        for text in texts:
            text.set_fontsize(12)

        for autotext in autotexts:
            autotext.set_color('white')
            autotext.set_fontsize(10)
            autotext.set_fontweight('bold')

        ax.set_title(title, fontsize=16, fontweight='bold', pad=20)

        plt.tight_layout()

        # ä¿å­˜
        Path(output_path).parent.mkdir(parents=True, exist_ok=True)
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        plt.close()

        logger.info(f"é¥¼å›¾å·²ç”Ÿæˆ: {output_path}")
        return output_path

    def plot_line_chart(
        self,
        data: Dict[str, List],
        title: str,
        xlabel: str,
        ylabel: str,
        output_path: str,
        figsize: Tuple[int, int] = (14, 6),
        markers: bool = True
    ) -> str:
        """
        ç»˜åˆ¶æŠ˜çº¿å›¾ï¼ˆæ”¯æŒå¤šæ¡çº¿ï¼‰

        Args:
            data: æ•°æ®å­—å…¸
                {
                    'ç³»åˆ—1': {'x': [1, 2, 3], 'y': [10, 20, 15]},
                    'ç³»åˆ—2': {'x': [1, 2, 3], 'y': [5, 15, 10]}
                }
            title: æ ‡é¢˜
            xlabel: X è½´æ ‡ç­¾
            ylabel: Y è½´æ ‡ç­¾
            output_path: è¾“å‡ºè·¯å¾„
            figsize: å›¾è¡¨å¤§å°
            markers: æ˜¯å¦æ˜¾ç¤ºæ ‡è®°ç‚¹

        Returns:
            str: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        fig, ax = plt.subplots(figsize=figsize)

        for label, values in data.items():
            marker = 'o' if markers else None
            ax.plot(
                values['x'],
                values['y'],
                label=label,
                marker=marker,
                linewidth=2,
                markersize=6
            )

        ax.set_title(title, fontsize=16, fontweight='bold', pad=20)
        ax.set_xlabel(xlabel, fontsize=12)
        ax.set_ylabel(ylabel, fontsize=12)

        # ç½‘æ ¼
        ax.grid(True, alpha=0.3, linestyle='--')

        # å›¾ä¾‹
        ax.legend(fontsize=10, loc='best')

        plt.tight_layout()

        # ä¿å­˜
        Path(output_path).parent.mkdir(parents=True, exist_ok=True)
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        plt.close()

        logger.info(f"æŠ˜çº¿å›¾å·²ç”Ÿæˆ: {output_path}")
        return output_path

    def plot_heatmap(
        self,
        data: List[List[float]],
        row_labels: List[str],
        col_labels: List[str],
        title: str,
        output_path: str,
        figsize: Tuple[int, int] = (14, 8),
        cmap: str = 'YlOrRd',
        annot: bool = True
    ) -> str:
        """
        ç»˜åˆ¶çƒ­åŠ›å›¾

        Args:
            data: æ•°æ®çŸ©é˜µ
            row_labels: è¡Œæ ‡ç­¾
            col_labels: åˆ—æ ‡ç­¾
            title: æ ‡é¢˜
            output_path: è¾“å‡ºè·¯å¾„
            figsize: å›¾è¡¨å¤§å°
            cmap: é¢œè‰²æ˜ å°„
            annot: æ˜¯å¦æ˜¾ç¤ºæ•°å€¼

        Returns:
            str: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        fig, ax = plt.subplots(figsize=figsize)

        sns.heatmap(
            data,
            cmap=cmap,
            annot=annot,
            fmt='.0f',
            linewidths=0.5,
            cbar_kws={'label': 'æ•°å€¼'},
            xticklabels=col_labels,
            yticklabels=row_labels,
            ax=ax
        )

        ax.set_title(title, fontsize=16, fontweight='bold', pad=20)

        plt.tight_layout()

        # ä¿å­˜
        Path(output_path).parent.mkdir(parents=True, exist_ok=True)
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        plt.close()

        logger.info(f"çƒ­åŠ›å›¾å·²ç”Ÿæˆ: {output_path}")
        return output_path
```

---

## 3.5 æŠ¥å‘Šç”Ÿæˆå™¨ï¼ˆreport_generator.pyï¼‰

### 3.5.1 æ ¸å¿ƒç±»è®¾è®¡

```python
"""
æŠ¥å‘Šç”Ÿæˆå™¨æ¨¡å—

åŠŸèƒ½ï¼š
1. HTML æŠ¥å‘Šç”Ÿæˆ
2. Markdown æŠ¥å‘Šç”Ÿæˆï¼ˆå¯é€‰ï¼‰
3. æ¨¡æ¿æ¸²æŸ“
4. å›¾è¡¨åµŒå…¥

ä¾èµ–ï¼š
- jinja2

ä½œè€…: Claude Sonnet 4.5
æ—¥æœŸ: 2026-02-14
"""

from typing import Dict, List, Optional
from pathlib import Path
from jinja2 import Template, Environment, FileSystemLoader
import base64
import logging

logger = logging.getLogger(__name__)


class ReportGenerator:
    """æŠ¥å‘Šç”Ÿæˆå™¨"""

    def __init__(self, template_dir: str = None):
        """
        åˆå§‹åŒ–æŠ¥å‘Šç”Ÿæˆå™¨

        Args:
            template_dir: æ¨¡æ¿ç›®å½•è·¯å¾„
        """
        if template_dir is None:
            template_dir = Path(__file__).parent / 'templates'

        self.template_dir = Path(template_dir)

        # åˆ›å»º Jinja2 ç¯å¢ƒ
        self.env = Environment(
            loader=FileSystemLoader(str(self.template_dir)),
            autoescape=True
        )

    def generate_html_report(
        self,
        data: Dict,
        output_path: str = "åˆ†ææŠ¥å‘Š/reports/index.html",
        embed_images: bool = True
    ) -> str:
        """
        ç”Ÿæˆ HTML æŠ¥å‘Š

        Args:
            data: æŠ¥å‘Šæ•°æ®
                {
                    'title': 'è®ºå›å½’æ¡£åˆ†ææŠ¥å‘Š',
                    'global_stats': {...},
                    'authors': [...],
                    'charts': {...},
                    'wordclouds': {...}
                }
            output_path: è¾“å‡ºè·¯å¾„
            embed_images: æ˜¯å¦åµŒå…¥å›¾ç‰‡ï¼ˆbase64ï¼‰

        Returns:
            str: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        # åŠ è½½æ¨¡æ¿
        template = self.env.get_template('report.html')

        # å›¾ç‰‡å¤„ç†
        if embed_images:
            data = self._embed_images(data)

        # æ¸²æŸ“
        html = template.render(**data)

        # ä¿å­˜
        Path(output_path).parent.mkdir(parents=True, exist_ok=True)
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(html)

        logger.info(f"HTML æŠ¥å‘Šå·²ç”Ÿæˆ: {output_path}")
        return output_path

    def _embed_images(self, data: Dict) -> Dict:
        """å°†å›¾ç‰‡è½¬ä¸º base64 åµŒå…¥"""
        # å¤„ç† charts
        if 'charts' in data:
            for key, path in data['charts'].items():
                if path and Path(path).exists():
                    data['charts'][key] = self._image_to_base64(path)

        # å¤„ç† wordclouds
        if 'wordclouds' in data:
            for key, path in data['wordclouds'].items():
                if path and Path(path).exists():
                    data['wordclouds'][key] = self._image_to_base64(path)

        return data

    def _image_to_base64(self, image_path: str) -> str:
        """å›¾ç‰‡è½¬ base64"""
        with open(image_path, 'rb') as f:
            image_data = f.read()
            b64_data = base64.b64encode(image_data).decode('utf-8')
            return f"data:image/png;base64,{b64_data}"

    def generate_markdown_report(
        self,
        data: Dict,
        output_path: str = "åˆ†ææŠ¥å‘Š/reports/report.md"
    ) -> str:
        """
        ç”Ÿæˆ Markdown æŠ¥å‘Šï¼ˆå¯é€‰ï¼‰

        Args:
            data: æŠ¥å‘Šæ•°æ®
            output_path: è¾“å‡ºè·¯å¾„

        Returns:
            str: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        # åŠ è½½æ¨¡æ¿
        template = self.env.get_template('report.md')

        # æ¸²æŸ“
        markdown = template.render(**data)

        # ä¿å­˜
        Path(output_path).parent.mkdir(parents=True, exist_ok=True)
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(markdown)

        logger.info(f"Markdown æŠ¥å‘Šå·²ç”Ÿæˆ: {output_path}")
        return output_path

    def generate_author_report(
        self,
        author_name: str,
        data: Dict,
        output_path: str = None
    ) -> str:
        """
        ç”Ÿæˆå•ä¸ªä½œè€…çš„è¯¦ç»†æŠ¥å‘Š

        Args:
            author_name: ä½œè€…å
            data: ä½œè€…æ•°æ®
            output_path: è¾“å‡ºè·¯å¾„

        Returns:
            str: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        if output_path is None:
            output_path = f"åˆ†ææŠ¥å‘Š/reports/author_{author_name}.html"

        # åŠ è½½æ¨¡æ¿
        template = self.env.get_template('author_report.html')

        # æ¸²æŸ“
        html = template.render(author_name=author_name, **data)

        # ä¿å­˜
        Path(output_path).parent.mkdir(parents=True, exist_ok=True)
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(html)

        logger.info(f"ä½œè€…æŠ¥å‘Šå·²ç”Ÿæˆ: {output_path}")
        return output_path
```

### 3.5.2 HTML æ¨¡æ¿è®¾è®¡

**æ–‡ä»¶**: `python/src/analysis/templates/report.html`

```html
<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>{{ title }}</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", "Microsoft YaHei", sans-serif;
            line-height: 1.6;
            color: #333;
            background: #f5f5f5;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
        }

        header {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 40px 20px;
            text-align: center;
            border-radius: 10px;
            margin-bottom: 30px;
            box-shadow: 0 4px 6px rgba(0,0,0,0.1);
        }

        h1 {
            font-size: 36px;
            margin-bottom: 10px;
        }

        .subtitle {
            font-size: 16px;
            opacity: 0.9;
        }

        .stats-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 20px;
            margin-bottom: 30px;
        }

        .stat-card {
            background: white;
            padding: 25px;
            border-radius: 10px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
            text-align: center;
        }

        .stat-value {
            font-size: 32px;
            font-weight: bold;
            color: #667eea;
            margin-bottom: 5px;
        }

        .stat-label {
            font-size: 14px;
            color: #666;
        }

        .section {
            background: white;
            padding: 30px;
            border-radius: 10px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
            margin-bottom: 30px;
        }

        .section-title {
            font-size: 24px;
            margin-bottom: 20px;
            padding-bottom: 10px;
            border-bottom: 2px solid #667eea;
        }

        .chart-container {
            margin: 20px 0;
            text-align: center;
        }

        .chart-container img {
            max-width: 100%;
            height: auto;
            border-radius: 5px;
            box-shadow: 0 2px 8px rgba(0,0,0,0.1);
        }

        .author-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 20px;
        }

        .author-card {
            background: #f9f9f9;
            padding: 20px;
            border-radius: 8px;
            border-left: 4px solid #667eea;
        }

        .author-name {
            font-size: 18px;
            font-weight: bold;
            margin-bottom: 10px;
        }

        .author-stats {
            font-size: 14px;
            color: #666;
        }

        footer {
            text-align: center;
            padding: 20px;
            color: #666;
            font-size: 14px;
        }

        @media (max-width: 768px) {
            .stats-grid {
                grid-template-columns: repeat(2, 1fr);
            }

            h1 {
                font-size: 28px;
            }

            .author-grid {
                grid-template-columns: 1fr;
            }
        }

        @media print {
            body {
                background: white;
            }

            .container {
                max-width: 100%;
            }

            .section {
                page-break-inside: avoid;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <!-- Header -->
        <header>
            <h1>{{ title }}</h1>
            <div class="subtitle">ç”Ÿæˆæ—¶é—´: {{ generation_time }}</div>
        </header>

        <!-- Global Stats -->
        <div class="stats-grid">
            <div class="stat-card">
                <div class="stat-value">{{ global_stats.total_authors }}</div>
                <div class="stat-label">å…³æ³¨ä½œè€…</div>
            </div>
            <div class="stat-card">
                <div class="stat-value">{{ global_stats.total_posts }}</div>
                <div class="stat-label">å½’æ¡£å¸–å­</div>
            </div>
            <div class="stat-card">
                <div class="stat-value">{{ global_stats.total_images }}</div>
                <div class="stat-label">å›¾ç‰‡æ€»æ•°</div>
            </div>
            <div class="stat-card">
                <div class="stat-value">{{ global_stats.total_videos }}</div>
                <div class="stat-label">è§†é¢‘æ€»æ•°</div>
            </div>
            <div class="stat-card">
                <div class="stat-value">{{ global_stats.total_size_gb }}</div>
                <div class="stat-label">æ€»å­˜å‚¨ç©ºé—´(GB)</div>
            </div>
        </div>

        <!-- Monthly Trend -->
        <div class="section">
            <h2 class="section-title">ğŸ“ˆ å‘å¸–æœˆåº¦è¶‹åŠ¿</h2>
            <div class="chart-container">
                {% if charts.monthly_trend %}
                <img src="{{ charts.monthly_trend }}" alt="æœˆåº¦è¶‹åŠ¿å›¾">
                {% else %}
                <p>æš‚æ— æ•°æ®</p>
                {% endif %}
            </div>
        </div>

        <!-- Time Heatmap -->
        <div class="section">
            <h2 class="section-title">ğŸŒ¡ï¸ å‘å¸–æ—¶é—´çƒ­åŠ›å›¾</h2>
            <div class="chart-container">
                {% if charts.time_heatmap %}
                <img src="{{ charts.time_heatmap }}" alt="æ—¶é—´çƒ­åŠ›å›¾">
                {% else %}
                <p>æš‚æ— æ•°æ®</p>
                {% endif %}
            </div>
        </div>

        <!-- Wordcloud -->
        <div class="section">
            <h2 class="section-title">â˜ï¸ å†…å®¹è¯äº‘</h2>
            <div class="chart-container">
                {% if wordclouds.global %}
                <img src="{{ wordclouds.global }}" alt="å…¨å±€è¯äº‘">
                {% else %}
                <p>æš‚æ— æ•°æ®</p>
                {% endif %}
            </div>
        </div>

        <!-- Camera Stats -->
        {% if charts.camera_ranking %}
        <div class="section">
            <h2 class="section-title">ğŸ“· ç›¸æœºä½¿ç”¨ç»Ÿè®¡</h2>
            <div class="chart-container">
                <img src="{{ charts.camera_ranking }}" alt="ç›¸æœºæ’è¡Œ">
            </div>
        </div>
        {% endif %}

        <!-- Author List -->
        <div class="section">
            <h2 class="section-title">ğŸ‘¥ ä½œè€…è¯¦æƒ…</h2>
            <div class="author-grid">
                {% for author in authors %}
                <div class="author-card">
                    <div class="author-name">{{ author.name }}</div>
                    <div class="author-stats">
                        ğŸ“ å¸–å­: {{ author.total_posts }} |
                        ğŸ–¼ï¸ å›¾ç‰‡: {{ author.total_images }} |
                        ğŸ¬ è§†é¢‘: {{ author.total_videos }}
                    </div>
                </div>
                {% endfor %}
            </div>
        </div>

        <!-- Footer -->
        <footer>
            <p>ğŸ¤– ç”± T66Y è®ºå›å½’æ¡£ç³»ç»Ÿè‡ªåŠ¨ç”Ÿæˆ</p>
            <p>Powered by Claude Sonnet 4.5</p>
        </footer>
    </div>
</body>
</html>
```

---

## 4. æ¥å£è§„èŒƒ

### 4.1 æ¨¡å—å¯¼å‡ºæ¥å£

**æ–‡ä»¶**: `python/src/analysis/__init__.py`

```python
"""
åˆ†ææ¨¡å—

Phase 4: æ•°æ®åˆ†æ + å¯è§†åŒ–

æ¨¡å—ç»“æ„:
- exif_analyzer.py: EXIF åˆ†æå™¨
- text_analyzer.py: æ–‡æœ¬åˆ†æå™¨
- time_analyzer.py: æ—¶é—´åˆ†æå™¨
- visualizer.py: å¯è§†åŒ–å™¨
- report_generator.py: æŠ¥å‘Šç”Ÿæˆå™¨

ä½œè€…: Claude Sonnet 4.5
æ—¥æœŸ: 2026-02-14
"""

from .exif_analyzer import ExifAnalyzer
from .text_analyzer import TextAnalyzer
from .time_analyzer import TimeAnalyzer
from .visualizer import Visualizer
from .report_generator import ReportGenerator

__all__ = [
    'ExifAnalyzer',
    'TextAnalyzer',
    'TimeAnalyzer',
    'Visualizer',
    'ReportGenerator',
]

__version__ = '1.0.0'
```

### 4.2 é«˜å±‚APIè®¾è®¡

```python
"""
é«˜å±‚ APIï¼ˆå¯é€‰ï¼‰

ç®€åŒ–å¸¸ç”¨æ“ä½œçš„æ¥å£

æ–‡ä»¶: python/src/analysis/api.py
"""

from typing import List, Dict, Optional
from database import get_default_connection
from .exif_analyzer import ExifAnalyzer
from .text_analyzer import TextAnalyzer
from .time_analyzer import TimeAnalyzer
from .visualizer import Visualizer
from .report_generator import ReportGenerator


def analyze_all(
    output_dir: str = "åˆ†ææŠ¥å‘Š",
    authors: List[str] = None
) -> Dict[str, str]:
    """
    ä¸€é”®ç”Ÿæˆæ‰€æœ‰åˆ†ææŠ¥å‘Š

    Args:
        output_dir: è¾“å‡ºç›®å½•
        authors: ä½œè€…åˆ—è¡¨ï¼ˆNone = å…¨éƒ¨ï¼‰

    Returns:
        dict: ç”Ÿæˆçš„æ–‡ä»¶è·¯å¾„
        {
            'wordclouds': [...],
            'charts': [...],
            'reports': [...]
        }
    """
    db = get_default_connection()

    # åˆå§‹åŒ–åˆ†æå™¨
    exif_analyzer = ExifAnalyzer(db)
    text_analyzer = TextAnalyzer(db)
    time_analyzer = TimeAnalyzer(db)
    visualizer = Visualizer()
    report_gen = ReportGenerator()

    results = {
        'wordclouds': [],
        'charts': [],
        'reports': []
    }

    # 1. è¯äº‘
    if authors:
        for author in authors:
            path = text_analyzer.generate_wordcloud(author_name=author)
            results['wordclouds'].append(path)
    else:
        path = text_analyzer.generate_wordcloud()
        results['wordclouds'].append(path)

    # 2. è¶‹åŠ¿å›¾
    path = time_analyzer.plot_monthly_trend()
    results['charts'].append(path)

    # 3. çƒ­åŠ›å›¾
    path = time_analyzer.plot_time_heatmap()
    results['charts'].append(path)

    # 4. ç›¸æœºç»Ÿè®¡
    camera_stats = exif_analyzer.get_camera_stats()
    if camera_stats:
        data = {item['model']: item['photo_count'] for item in camera_stats}
        path = visualizer.plot_bar_chart(
            data,
            "ç›¸æœºä½¿ç”¨æ’è¡Œ",
            "ç›¸æœºå‹å·",
            "ç…§ç‰‡æ•°",
            f"{output_dir}/charts/camera_ranking.png"
        )
        results['charts'].append(path)

    # 5. HTML æŠ¥å‘Š
    report_data = {
        'title': 'è®ºå›å½’æ¡£åˆ†ææŠ¥å‘Š',
        'generation_time': '2026-02-14',
        'global_stats': {},  # ä»æ•°æ®åº“è·å–
        'authors': [],       # ä»æ•°æ®åº“è·å–
        'charts': {},
        'wordclouds': {}
    }
    path = report_gen.generate_html_report(report_data)
    results['reports'].append(path)

    return results


def analyze_author(author_name: str, output_dir: str = "åˆ†ææŠ¥å‘Š") -> Dict[str, str]:
    """
    åˆ†æå•ä¸ªä½œè€…

    Args:
        author_name: ä½œè€…å
        output_dir: è¾“å‡ºç›®å½•

    Returns:
        dict: ç”Ÿæˆçš„æ–‡ä»¶è·¯å¾„
    """
    db = get_default_connection()

    results = {}

    # è¯äº‘
    text_analyzer = TextAnalyzer(db)
    results['wordcloud'] = text_analyzer.generate_wordcloud(author_name=author_name)

    # è¶‹åŠ¿å›¾
    time_analyzer = TimeAnalyzer(db)
    results['trend'] = time_analyzer.plot_monthly_trend(author_name=author_name)

    # çƒ­åŠ›å›¾
    results['heatmap'] = time_analyzer.plot_time_heatmap(author_name=author_name)

    # æ´»è·ƒåº¦åˆ†æ
    results['active_patterns'] = time_analyzer.analyze_active_patterns(author_name=author_name)

    return results
```

---

## 5. é…ç½®è®¾è®¡

### 5.1 å­—ä½“é…ç½®æ¨¡å—

**æ–‡ä»¶**: `python/src/utils/font_config.py`

```python
"""
å­—ä½“é…ç½®æ¨¡å—

åŠŸèƒ½ï¼š
1. è‡ªåŠ¨æ£€æµ‹ç³»ç»Ÿä¸­æ–‡å­—ä½“
2. é…ç½® matplotlib ä¸­æ–‡æ˜¾ç¤º
3. æä¾›å­—ä½“è·¯å¾„æŸ¥è¯¢

ä½œè€…: Claude Sonnet 4.5
æ—¥æœŸ: 2026-02-14
"""

import platform
import os
from pathlib import Path
from typing import Optional, List
import logging

logger = logging.getLogger(__name__)


class FontConfig:
    """å­—ä½“é…ç½®å™¨"""

    # å­—ä½“è·¯å¾„æ˜ å°„
    FONT_PATHS = {
        'Linux': [
            '/usr/share/fonts/truetype/wqy/wqy-zenhei.ttc',
            '/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc',
            '/usr/share/fonts/truetype/arphic/uming.ttc',
        ],
        'Darwin': [  # macOS
            '/System/Library/Fonts/PingFang.ttc',
            '/System/Library/Fonts/Hiragino Sans GB.ttc',
            '/Library/Fonts/Arial Unicode.ttf',
        ],
        'Windows': [
            'C:/Windows/Fonts/msyh.ttc',    # å¾®è½¯é›…é»‘
            'C:/Windows/Fonts/simhei.ttf',  # é»‘ä½“
            'C:/Windows/Fonts/simsun.ttc',  # å®‹ä½“
        ]
    }

    def __init__(self):
        """åˆå§‹åŒ–å­—ä½“é…ç½®"""
        self.system = platform.system()
        self.font_path = self.detect_chinese_font()

    def detect_chinese_font(self) -> Optional[str]:
        """
        è‡ªåŠ¨æ£€æµ‹ç³»ç»Ÿä¸­æ–‡å­—ä½“

        Returns:
            str: å­—ä½“æ–‡ä»¶è·¯å¾„
            None: æœªæ‰¾åˆ°å­—ä½“
        """
        paths = self.FONT_PATHS.get(self.system, [])

        for path in paths:
            if os.path.exists(path):
                logger.info(f"æ‰¾åˆ°ä¸­æ–‡å­—ä½“: {path}")
                return path

        logger.warning(f"æœªæ‰¾åˆ°ä¸­æ–‡å­—ä½“ï¼ˆç³»ç»Ÿ: {self.system}ï¼‰")
        return None

    def setup_matplotlib_font(self) -> bool:
        """
        é…ç½® matplotlib ä¸­æ–‡å­—ä½“

        Returns:
            bool: é…ç½®æˆåŠŸ
        """
        import matplotlib
        import matplotlib.font_manager as fm

        if self.font_path:
            # æ·»åŠ å­—ä½“
            fm.fontManager.addfont(self.font_path)

            # è·å–å­—ä½“åç§°
            font_prop = fm.FontProperties(fname=self.font_path)
            font_name = font_prop.get_name()

            # é…ç½® matplotlib
            matplotlib.rcParams['font.sans-serif'] = [font_name, 'DejaVu Sans']
            matplotlib.rcParams['axes.unicode_minus'] = False

            logger.info(f"matplotlib ä¸­æ–‡å­—ä½“é…ç½®æˆåŠŸ: {font_name}")
            return True
        else:
            # é™çº§é…ç½®
            matplotlib.rcParams['font.sans-serif'] = ['DejaVu Sans']
            matplotlib.rcParams['axes.unicode_minus'] = False

            logger.warning("ä½¿ç”¨é™çº§é…ç½®ï¼Œä¸­æ–‡å¯èƒ½æ˜¾ç¤ºä¸ºæ–¹æ¡†")
            return False

    def get_font_path(self) -> Optional[str]:
        """è·å–å­—ä½“è·¯å¾„"""
        return self.font_path

    def test_chinese_display(self) -> bool:
        """
        æµ‹è¯•ä¸­æ–‡æ˜¾ç¤º

        Returns:
            bool: ä¸­æ–‡æ˜¾ç¤ºæ­£å¸¸
        """
        import matplotlib.pyplot as plt

        try:
            fig, ax = plt.subplots(figsize=(6, 4))
            ax.text(0.5, 0.5, 'æµ‹è¯•ä¸­æ–‡æ˜¾ç¤º', fontsize=20, ha='center', va='center')
            ax.set_title('ä¸­æ–‡å­—ä½“æµ‹è¯•')

            test_path = 'test_chinese_font.png'
            plt.savefig(test_path, dpi=100)
            plt.close()

            # æ£€æŸ¥æ–‡ä»¶
            if os.path.exists(test_path):
                logger.info("ä¸­æ–‡æ˜¾ç¤ºæµ‹è¯•é€šè¿‡")
                os.remove(test_path)
                return True

        except Exception as e:
            logger.error(f"ä¸­æ–‡æ˜¾ç¤ºæµ‹è¯•å¤±è´¥: {e}")

        return False
```

### 5.2 åœç”¨è¯è¡¨

**æ–‡ä»¶**: `python/src/utils/stopwords.txt`

```
# ä¸­æ–‡åœç”¨è¯è¡¨
# ç”¨äºè¯äº‘ç”Ÿæˆæ—¶è¿‡æ»¤æ— æ„ä¹‰è¯æ±‡

# ä»£è¯
çš„
äº†
åœ¨
æ˜¯
æˆ‘
ä½ 
ä»–
å¥¹
å®ƒ
ä»¬
è¿™
é‚£
å“ª
è°
ä»€ä¹ˆ

# åŠ¨è¯
æœ‰
å’Œ
å°±
ä¸
éƒ½
ä¼š
è¦
å»
è¯´
çœ‹
åš

# å‰¯è¯
ä¹Ÿ
å¾ˆ
è¿˜
åˆ
å†
æ›´
æœ€
åª
æ‰
èƒ½
å¯ä»¥

# è¿è¯
ä¸
æˆ–
ä½†æ˜¯
ç„¶å
å› ä¸º
æ‰€ä»¥
è™½ç„¶
å¦‚æœ

# é‡è¯
ä¸€
ä¸€ä¸ª
ä¸€äº›
å‡ ä¸ª

# å…¶ä»–
ä¸Š
ä¸‹
ä¸­
é‡Œ
å¤–
å‰
å
å·¦
å³
```

---

## 6. æµ‹è¯•è®¾è®¡

### 6.1 å•å…ƒæµ‹è¯•

**æ–‡ä»¶**: `test_phase4_analysis.py`

```python
"""
Phase 4 åˆ†ææ¨¡å—å•å…ƒæµ‹è¯•

è¿è¡Œ: pytest test_phase4_analysis.py -v

ä½œè€…: Claude Sonnet 4.5
æ—¥æœŸ: 2026-02-14
"""

import pytest
from pathlib import Path
from analysis import (
    ExifAnalyzer,
    TextAnalyzer,
    TimeAnalyzer,
    Visualizer,
    ReportGenerator
)


class TestExifAnalyzer:
    """EXIF åˆ†æå™¨æµ‹è¯•"""

    def test_extract_exif_basic(self):
        """æµ‹è¯•åŸºç¡€ EXIF æå–"""
        analyzer = ExifAnalyzer()
        # éœ€è¦å‡†å¤‡æµ‹è¯•å›¾ç‰‡
        # exif = analyzer.extract_exif('test_data/photo_with_exif.jpg')
        # assert 'make' in exif

    def test_extract_gps(self):
        """æµ‹è¯• GPS æå–"""
        pass

    def test_reverse_geocode(self):
        """æµ‹è¯• GPS åæŸ¥"""
        analyzer = ExifAnalyzer()
        location = analyzer.reverse_geocode(39.9042, 116.4074)
        assert location is not None
        assert 'åŒ—äº¬' in location


class TestTextAnalyzer:
    """æ–‡æœ¬åˆ†æå™¨æµ‹è¯•"""

    def test_segment(self):
        """æµ‹è¯•ä¸­æ–‡åˆ†è¯"""
        analyzer = TextAnalyzer()
        text = "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æœ¬"
        words = analyzer.segment(text)
        assert len(words) > 0

    def test_calculate_word_freq(self):
        """æµ‹è¯•è¯é¢‘ç»Ÿè®¡"""
        analyzer = TextAnalyzer()
        text = "ç¾å¥³ ç¾å¥³ æ€§æ„Ÿ æ€§æ„Ÿ æ€§æ„Ÿ"
        freq = analyzer.calculate_word_freq(text)
        assert freq['æ€§æ„Ÿ'] > freq['ç¾å¥³']

    def test_generate_wordcloud(self):
        """æµ‹è¯•è¯äº‘ç”Ÿæˆ"""
        # éœ€è¦æ–‡æœ¬æ•°æ®
        pass


class TestTimeAnalyzer:
    """æ—¶é—´åˆ†æå™¨æµ‹è¯•"""

    def test_get_monthly_trend(self):
        """æµ‹è¯•è·å–æœˆåº¦è¶‹åŠ¿"""
        # éœ€è¦æ•°æ®åº“è¿æ¥
        pass

    def test_analyze_active_patterns(self):
        """æµ‹è¯•æ´»è·ƒåº¦åˆ†æ"""
        # éœ€è¦æ•°æ®åº“è¿æ¥
        pass


class TestVisualizer:
    """å¯è§†åŒ–å™¨æµ‹è¯•"""

    def test_plot_bar_chart(self):
        """æµ‹è¯•æŸ±çŠ¶å›¾"""
        vis = Visualizer()
        data = {'A': 10, 'B': 20, 'C': 15}
        output = 'test_output/bar_chart.png'
        path = vis.plot_bar_chart(
            data,
            'æµ‹è¯•æŸ±çŠ¶å›¾',
            'Xè½´',
            'Yè½´',
            output
        )
        assert Path(path).exists()

    def test_plot_pie_chart(self):
        """æµ‹è¯•é¥¼å›¾"""
        pass


class TestReportGenerator:
    """æŠ¥å‘Šç”Ÿæˆå™¨æµ‹è¯•"""

    def test_generate_html_report(self):
        """æµ‹è¯• HTML æŠ¥å‘Šç”Ÿæˆ"""
        gen = ReportGenerator()
        data = {
            'title': 'æµ‹è¯•æŠ¥å‘Š',
            'generation_time': '2026-02-14',
            'global_stats': {
                'total_authors': 9,
                'total_posts': 350
            },
            'authors': [],
            'charts': {},
            'wordclouds': {}
        }
        output = 'test_output/test_report.html'
        path = gen.generate_html_report(data, output)
        assert Path(path).exists()


# è¿è¡Œæµ‹è¯•
if __name__ == '__main__':
    pytest.main([__file__, '-v'])
```

---

## 7. å®æ–½ä»»åŠ¡æ¸…å•

### 7.1 ä»»åŠ¡åˆ†è§£ï¼ˆWeek 1-3ï¼Œå…±35ä¸ªä»»åŠ¡ï¼‰

**æ ¼å¼**: `[Task #XX] ä»»åŠ¡åç§°ï¼ˆå·¥ä½œé‡ï¼‰`

#### Week 1: å›¾ç‰‡å…ƒæ•°æ®ï¼ˆ5 å¤©ï¼‰

**Day 1: æ•°æ®åº“æ‰©å±•ï¼ˆ0.5 å¤©ï¼‰**
- [Task #26] åˆ›å»º `schema_v2.sql`ï¼ˆ0.5 å¤©ï¼‰

**Day 2: EXIF åˆ†æå™¨ï¼ˆ1 å¤©ï¼‰**
- [Task #27] åˆ›å»º `exif_analyzer.py` åŸºç¡€æ¡†æ¶ï¼ˆ0.5 å¤©ï¼‰
- [Task #28] å®ç° `extract_exif()` æ–¹æ³•ï¼ˆ0.5 å¤©ï¼‰

**Day 3: EXIF æå–é›†æˆï¼ˆ1 å¤©ï¼‰**
- [Task #29] ä¿®æ”¹ `downloader.py` ä¸‹è½½æ—¶æå– EXIFï¼ˆ0.5 å¤©ï¼‰
- [Task #30] å®ç° GPS æå–å’ŒåæŸ¥ï¼ˆ0.5 å¤©ï¼‰

**Day 4: å†å²æ•°æ®è¿ç§»ï¼ˆ1 å¤©ï¼‰**
- [Task #31] åˆ›å»º `migrate_exif.py`ï¼ˆ0.5 å¤©ï¼‰
- [Task #32] å®ç°æ‰¹é‡ EXIF æ‰«æï¼ˆ0.5 å¤©ï¼‰

**Day 5: ç…§ç‰‡æ°´å°æ˜¾ç¤ºï¼ˆ1 å¤©ï¼‰**
- [Task #33] ä¿®æ”¹ `archiver.py` HTML ç”Ÿæˆï¼ˆ0.5 å¤©ï¼‰
- [Task #34] è®¾è®¡æ°´å° CSS æ ·å¼ï¼ˆ0.5 å¤©ï¼‰

---

#### Week 2: æ–‡æœ¬ä¸æ—¶é—´åˆ†æï¼ˆ5 å¤©ï¼‰

**Day 6: æ–‡æœ¬åˆ†æå™¨åŸºç¡€ï¼ˆ1 å¤©ï¼‰**
- [Task #35] åˆ›å»º `text_analyzer.py`ï¼ˆ0.5 å¤©ï¼‰
- [Task #36] å®ç°ä¸­æ–‡åˆ†è¯å’Œè¯é¢‘ç»Ÿè®¡ï¼ˆ0.5 å¤©ï¼‰

**Day 7: è¯äº‘ç”Ÿæˆï¼ˆ1 å¤©ï¼‰**
- [Task #37] å®ç°è¯äº‘ç”Ÿæˆå™¨ï¼ˆ0.5 å¤©ï¼‰
- [Task #38] é…ç½®ä¸­æ–‡å­—ä½“ï¼ˆ`font_config.py`ï¼‰ï¼ˆ0.5 å¤©ï¼‰

**Day 8: æ—¶é—´åˆ†æå™¨åŸºç¡€ï¼ˆ1 å¤©ï¼‰**
- [Task #39] åˆ›å»º `time_analyzer.py`ï¼ˆ0.5 å¤©ï¼‰
- [Task #40] å®ç°æœˆåº¦è¶‹åŠ¿åˆ†æï¼ˆ0.5 å¤©ï¼‰

**Day 9: æ—¶é—´çƒ­åŠ›å›¾ï¼ˆ1 å¤©ï¼‰**
- [Task #41] å®ç°æ—¶é—´çƒ­åŠ›å›¾ï¼ˆ0.5 å¤©ï¼‰
- [Task #42] å®ç°æ´»è·ƒåº¦åˆ†æï¼ˆ0.5 å¤©ï¼‰

**Day 10: ç›¸æœºç»Ÿè®¡ï¼ˆ1 å¤©ï¼‰**
- [Task #43] å®ç°ç›¸æœºç»Ÿè®¡æŸ¥è¯¢ï¼ˆ0.5 å¤©ï¼‰
- [Task #44] ç»˜åˆ¶ç›¸æœºæ’è¡Œå›¾è¡¨ï¼ˆ0.5 å¤©ï¼‰

---

#### Week 3: å¯è§†åŒ–ä¸æŠ¥å‘Šï¼ˆ5 å¤©ï¼‰

**Day 11: å¯è§†åŒ–å™¨ï¼ˆ1 å¤©ï¼‰**
- [Task #45] åˆ›å»º `visualizer.py`ï¼ˆ0.5 å¤©ï¼‰
- [Task #46] å®ç°å„ç±»å›¾è¡¨æ–¹æ³•ï¼ˆ0.5 å¤©ï¼‰

**Day 12: å›¾è¡¨ç¾åŒ–ï¼ˆ1 å¤©ï¼‰**
- [Task #47] ç»Ÿä¸€å›¾è¡¨æ ·å¼é…ç½®ï¼ˆ0.5 å¤©ï¼‰
- [Task #48] é«˜æ¸…è¾“å‡ºé…ç½®ï¼ˆ0.5 å¤©ï¼‰

**Day 13: æŠ¥å‘Šç”Ÿæˆå™¨ï¼ˆ1 å¤©ï¼‰**
- [Task #49] åˆ›å»º `report_generator.py`ï¼ˆ0.5 å¤©ï¼‰
- [Task #50] è®¾è®¡ HTML æ¨¡æ¿ï¼ˆ0.5 å¤©ï¼‰

**Day 14: æŠ¥å‘Šé›†æˆï¼ˆ1 å¤©ï¼‰**
- [Task #51] å®ç°æŠ¥å‘Šæ•°æ®å‡†å¤‡ï¼ˆ0.5 å¤©ï¼‰
- [Task #52] å®ç°å›¾ç‰‡åµŒå…¥ï¼ˆ0.5 å¤©ï¼‰

**Day 15: èœå•é›†æˆä¸æµ‹è¯•ï¼ˆ1 å¤©ï¼‰**
- [Task #53] åˆ›å»º `analysis_menu.py`ï¼ˆ0.5 å¤©ï¼‰
- [Task #54] é›†æˆåˆ°ä¸»èœå•ï¼ˆ0.5 å¤©ï¼‰

---

### 7.2 ä»»åŠ¡ä¾èµ–å…³ç³»

```
Task #26 (schema_v2.sql)
  â”œâ”€> Task #27 (exif_analyzeråŸºç¡€)
  â”‚     â”œâ”€> Task #28 (extract_exif)
  â”‚     â”‚     â”œâ”€> Task #29 (downloaderé›†æˆ)
  â”‚     â”‚     â””â”€> Task #30 (GPSæå–)
  â”‚     â””â”€> Task #31 (migrate_exif)
  â”‚           â””â”€> Task #32 (æ‰¹é‡æ‰«æ)
  â”‚
  â”œâ”€> Task #35 (text_analyzer)
  â”‚     â”œâ”€> Task #36 (åˆ†è¯)
  â”‚     â””â”€> Task #37 (è¯äº‘)
  â”‚           â””â”€> Task #38 (å­—ä½“é…ç½®)
  â”‚
  â”œâ”€> Task #39 (time_analyzer)
  â”‚     â”œâ”€> Task #40 (æœˆåº¦è¶‹åŠ¿)
  â”‚     â”œâ”€> Task #41 (çƒ­åŠ›å›¾)
  â”‚     â””â”€> Task #42 (æ´»è·ƒåº¦)
  â”‚
  â”œâ”€> Task #43 (ç›¸æœºç»Ÿè®¡)
  â”‚     â””â”€> Task #44 (ç›¸æœºå›¾è¡¨)
  â”‚
  â”œâ”€> Task #45 (visualizer)
  â”‚     â”œâ”€> Task #46 (å›¾è¡¨æ–¹æ³•)
  â”‚     â”œâ”€> Task #47 (æ ·å¼é…ç½®)
  â”‚     â””â”€> Task #48 (é«˜æ¸…è¾“å‡º)
  â”‚
  â””â”€> Task #49 (report_generator)
        â”œâ”€> Task #50 (HTMLæ¨¡æ¿)
        â”œâ”€> Task #51 (æ•°æ®å‡†å¤‡)
        â””â”€> Task #52 (å›¾ç‰‡åµŒå…¥)
              â””â”€> Task #53 (analysis_menu)
                    â””â”€> Task #54 (èœå•é›†æˆ)
```

---

## 8. éªŒæ”¶æ ‡å‡†

### 8.1 åŠŸèƒ½éªŒæ”¶

| éªŒæ”¶é¡¹ | æ ‡å‡† | æµ‹è¯•æ–¹æ³• | ä¼˜å…ˆçº§ |
|--------|------|----------|--------|
| **EXIF æå–** | æ‰€æœ‰å›¾ç‰‡ EXIF æ•°æ®å®Œæ•´ | éšæœºæŠ½æŸ¥ 100 å¼  | P0 |
| **ç…§ç‰‡æ°´å°** | å½’æ¡£é¡µé¢æ­£ç¡®æ˜¾ç¤ºæ°´å° | æµè§ˆå™¨æµ‹è¯• | P0 |
| **GPS åæŸ¥** | æˆåŠŸç‡ > 90% | ç»Ÿè®¡åæŸ¥ç»“æœ | P1 |
| **è¯äº‘ç”Ÿæˆ** | ä¸­æ–‡æ— ä¹±ç ï¼Œè¯äº‘æ¸…æ™° | è§†è§‰æ£€æŸ¥ | P0 |
| **æ—¶é—´çƒ­åŠ›å›¾** | æ•°æ®å‡†ç¡®ï¼Œé¢œè‰²åŒºåˆ†æ¸…æ™° | å¯¹æ¯”æ•°æ®åº“ | P0 |
| **æœˆåº¦è¶‹åŠ¿å›¾** | æŠ˜çº¿æ¸…æ™°ï¼Œæ ‡ç­¾å®Œæ•´ | è§†è§‰æ£€æŸ¥ | P0 |
| **ç›¸æœºç»Ÿè®¡** | æ•°æ®å‡†ç¡®ï¼ŒTop 10 æ’è¡Œæ­£ç¡® | å¯¹æ¯”æ•°æ®åº“ | P1 |
| **HTML æŠ¥å‘Š** | åŒ…å«æ‰€æœ‰åˆ†æå†…å®¹ï¼Œæ ·å¼ç¾è§‚ | å¤šæµè§ˆå™¨æµ‹è¯• | P0 |
| **å“åº”å¼è®¾è®¡** | æ‰‹æœº/å¹³æ¿/æ¡Œé¢é€‚é… | å¤šè®¾å¤‡æµ‹è¯• | P1 |

### 8.2 æ€§èƒ½éªŒæ”¶

| æŒ‡æ ‡ | ç›®æ ‡ | æµ‹è¯•æ–¹æ³• | ä¼˜å…ˆçº§ |
|------|------|----------|--------|
| EXIF æå–é€Ÿåº¦ | > 10 å¼ /ç§’ | æ‰¹é‡æå– 100 å¼ è®¡æ—¶ | P0 |
| GPS åæŸ¥é€Ÿåº¦ | < 2 ç§’/æ¬¡ | å•æ¬¡åæŸ¥è®¡æ—¶ | P1 |
| è¯äº‘ç”Ÿæˆæ—¶é—´ | < 5 ç§’ | å•ä½œè€…è¯äº‘è®¡æ—¶ | P0 |
| çƒ­åŠ›å›¾ç”Ÿæˆæ—¶é—´ | < 2 ç§’ | å…¨å±€çƒ­åŠ›å›¾è®¡æ—¶ | P0 |
| HTML æŠ¥å‘Šç”Ÿæˆ | < 10 ç§’ | å®Œæ•´æŠ¥å‘Šè®¡æ—¶ | P0 |
| æŠ¥å‘Šæ–‡ä»¶å¤§å° | < 10 MB | æ£€æŸ¥æ–‡ä»¶å¤§å° | P1 |

### 8.3 è´¨é‡éªŒæ”¶

| æŒ‡æ ‡ | ç›®æ ‡ | æµ‹è¯•æ–¹æ³• | ä¼˜å…ˆçº§ |
|------|------|----------|--------|
| ä»£ç è¦†ç›–ç‡ | > 80% | pytest --cov | P1 |
| å•å…ƒæµ‹è¯•é€šè¿‡ç‡ | 100% | pytest | P0 |
| ä¸­æ–‡æ˜¾ç¤º | æ— ä¹±ç  | å¤šå¹³å°æµ‹è¯• | P0 |
| å›¾è¡¨è´¨é‡ | DPI 300ï¼Œæ¸…æ™° | è§†è§‰æ£€æŸ¥ | P0 |
| æŠ¥å‘Šç¾è§‚åº¦ | ç¬¦åˆè®¾è®¡è§„èŒƒ | è®¾è®¡å¸ˆå®¡æŸ¥ | P1 |

### 8.4 éªŒæ”¶æµ‹è¯•ç”¨ä¾‹

**æµ‹è¯•ç”¨ä¾‹ 1ï¼šEXIF æå–å®Œæ•´æ€§**
```
å‰ç½®æ¡ä»¶ï¼šæ•°æ®åº“ä¸­æœ‰ 1,000 å¼ å›¾ç‰‡è®°å½•
æµ‹è¯•æ­¥éª¤ï¼š
1. è¿è¡Œ EXIF æ‰¹é‡æ‰«æ
2. ç»Ÿè®¡æå–æˆåŠŸç‡
3. æ£€æŸ¥å­—æ®µå®Œæ•´æ€§
é¢„æœŸç»“æœï¼š
- æˆåŠŸç‡ > 95%
- ä¸»è¦å­—æ®µï¼ˆmake/model/datetimeï¼‰å®Œæ•´ç‡ > 90%
```

**æµ‹è¯•ç”¨ä¾‹ 2ï¼šè¯äº‘ä¸­æ–‡æ˜¾ç¤º**
```
å‰ç½®æ¡ä»¶ï¼šå·²æœ‰å¸–å­æ ‡é¢˜æ•°æ®
æµ‹è¯•æ­¥éª¤ï¼š
1. ç”Ÿæˆå•ä½œè€…è¯äº‘
2. ç”Ÿæˆå…¨å±€è¯äº‘
3. åœ¨å¤šä¸ªå¹³å°æŸ¥çœ‹ï¼ˆLinux/macOS/Windowsï¼‰
é¢„æœŸç»“æœï¼š
- æ‰€æœ‰å¹³å°ä¸­æ–‡æ˜¾ç¤ºæ­£å¸¸ï¼Œæ— ä¹±ç 
- è¯äº‘å›¾æ¸…æ™°ï¼ŒDPI 300
```

**æµ‹è¯•ç”¨ä¾‹ 3ï¼šHTML æŠ¥å‘ŠåŠŸèƒ½**
```
å‰ç½®æ¡ä»¶ï¼šå·²ç”Ÿæˆæ‰€æœ‰å›¾è¡¨
æµ‹è¯•æ­¥éª¤ï¼š
1. ç”Ÿæˆ HTML æŠ¥å‘Š
2. åœ¨å¤šä¸ªæµè§ˆå™¨æ‰“å¼€ï¼ˆChrome/Firefox/Safariï¼‰
3. æµ‹è¯•å“åº”å¼è®¾è®¡ï¼ˆè°ƒæ•´çª—å£å¤§å°ï¼‰
4. æµ‹è¯•æ‰“å°åŠŸèƒ½
é¢„æœŸç»“æœï¼š
- æ‰€æœ‰æµè§ˆå™¨æ˜¾ç¤ºæ­£å¸¸
- å“åº”å¼å¸ƒå±€æ­£ç¡®
- æ‰“å°æ ¼å¼å‹å¥½
```

**æµ‹è¯•ç”¨ä¾‹ 4ï¼šç…§ç‰‡æ°´å°æ˜¾ç¤º**
```
å‰ç½®æ¡ä»¶ï¼šå·²å½’æ¡£å¸–å­åŒ…å«å›¾ç‰‡
æµ‹è¯•æ­¥éª¤ï¼š
1. æ‰“å¼€å½’æ¡£é¡µé¢
2. æŸ¥çœ‹å›¾ç‰‡æ°´å°
3. æµ‹è¯•å¤šç§è®¾å¤‡ï¼ˆæ‰‹æœº/å¹³æ¿/æ¡Œé¢ï¼‰
é¢„æœŸç»“æœï¼š
- æ°´å°ä¿¡æ¯å®Œæ•´ï¼ˆç›¸æœº/æ—¶é—´/åœ°ç‚¹ï¼‰
- æ ·å¼ç¾è§‚
- å¤šè®¾å¤‡é€‚é…
```

---

## 9. å®æ–½æ£€æŸ¥æ¸…å•

### 9.1 ç¯å¢ƒå‡†å¤‡

- [ ] å®‰è£…ä¾èµ–åº“ï¼ˆ`pip install -r requirements.txt`ï¼‰
- [ ] å®‰è£…ä¸­æ–‡å­—ä½“ï¼ˆLinux: `apt install fonts-wqy-zenhei`ï¼‰
- [ ] æµ‹è¯•ä¸­æ–‡æ˜¾ç¤ºï¼ˆè¿è¡Œ `font_config.test_chinese_display()`ï¼‰
- [ ] å‡†å¤‡æµ‹è¯•æ•°æ®ï¼ˆEXIF å›¾ç‰‡ã€æ–‡æœ¬æ•°æ®ï¼‰

### 9.2 Week 1 æ£€æŸ¥æ¸…å•

- [ ] Task #26: schema_v2.sql åˆ›å»º
- [ ] Task #27-28: exif_analyzer.py åŸºç¡€åŠŸèƒ½
- [ ] Task #29-30: downloader.py é›†æˆ + GPS
- [ ] Task #31-32: migrate_exif.py æ‰¹é‡æ‰«æ
- [ ] Task #33-34: archiver.py æ°´å°æ˜¾ç¤º
- [ ] Week 1 éªŒæ”¶ï¼šæ‰€æœ‰å›¾ç‰‡ EXIF æå–å®Œæˆ

### 9.3 Week 2 æ£€æŸ¥æ¸…å•

- [ ] Task #35-36: text_analyzer.py åˆ†è¯
- [ ] Task #37-38: è¯äº‘ç”Ÿæˆ + å­—ä½“é…ç½®
- [ ] Task #39-40: time_analyzer.py è¶‹åŠ¿åˆ†æ
- [ ] Task #41-42: çƒ­åŠ›å›¾ + æ´»è·ƒåº¦
- [ ] Task #43-44: ç›¸æœºç»Ÿè®¡
- [ ] Week 2 éªŒæ”¶ï¼šè¯äº‘å’Œçƒ­åŠ›å›¾ç”Ÿæˆæ­£å¸¸

### 9.4 Week 3 æ£€æŸ¥æ¸…å•

- [ ] Task #45-46: visualizer.py å›¾è¡¨æ–¹æ³•
- [ ] Task #47-48: å›¾è¡¨ç¾åŒ– + é«˜æ¸…è¾“å‡º
- [ ] Task #49-50: report_generator.py + æ¨¡æ¿
- [ ] Task #51-52: æŠ¥å‘Šæ•°æ®å‡†å¤‡ + å›¾ç‰‡åµŒå…¥
- [ ] Task #53-54: analysis_menu.py + èœå•é›†æˆ
- [ ] Week 3 éªŒæ”¶ï¼šHTML æŠ¥å‘Šå®Œæ•´ç¾è§‚

### 9.5 æœ€ç»ˆæ£€æŸ¥æ¸…å•

- [ ] æ‰€æœ‰å•å…ƒæµ‹è¯•é€šè¿‡ï¼ˆpytestï¼‰
- [ ] ä»£ç è¦†ç›–ç‡ > 80%
- [ ] ä¸­æ–‡æ˜¾ç¤ºæ— ä¹±ç ï¼ˆå¤šå¹³å°æµ‹è¯•ï¼‰
- [ ] HTML æŠ¥å‘Šç¾è§‚ï¼ˆå¤šæµè§ˆå™¨æµ‹è¯•ï¼‰
- [ ] æ€§èƒ½è¾¾æ ‡ï¼ˆæ‰€æœ‰æŒ‡æ ‡ï¼‰
- [ ] æ–‡æ¡£æ›´æ–°ï¼ˆREADMEã€FEATURES_DESIGN_OVERVIEWï¼‰
- [ ] GitHub æäº¤ï¼ˆæ ‡æ³¨"Mile3å®Œæˆ"ï¼‰

---

## 10. é£é™©ç¼“è§£æªæ–½

### 10.1 æŠ€æœ¯é£é™©ç¼“è§£

**é£é™© 1ï¼šä¸­æ–‡ä¹±ç **
- ç¼“è§£ï¼šæå‰é…ç½®å­—ä½“ï¼Œä½¿ç”¨ `font_config.py` è‡ªåŠ¨æ£€æµ‹
- å›é€€ï¼šä½¿ç”¨è‹±æ–‡æ ‡ç­¾ï¼Œæˆ–æä¾›æ‰‹åŠ¨é…ç½®é€‰é¡¹

**é£é™© 2ï¼šEXIF æ•°æ®ç¼ºå¤±**
- ç¼“è§£ï¼šå®¹é”™å¤„ç†ï¼Œå­—æ®µå¯é€‰
- å›é€€ï¼šéƒ¨åˆ†å­—æ®µæ˜¾ç¤º"æœªçŸ¥"

**é£é™© 3ï¼šGPS åæŸ¥å¤±è´¥**
- ç¼“è§£ï¼šç¼“å­˜ç»“æœï¼Œå¤±è´¥æ—¶æ˜¾ç¤ºåæ ‡
- å›é€€ï¼šä¸æ˜¾ç¤ºåœ°ç†ä½ç½®ï¼Œåªæ˜¾ç¤ºåæ ‡

**é£é™© 4ï¼šä¾èµ–åº“å†²çª**
- ç¼“è§£ï¼šé”å®šç‰ˆæœ¬ï¼Œä½¿ç”¨è™šæ‹Ÿç¯å¢ƒ
- å›é€€ï¼šé™çº§ä¾èµ–ç‰ˆæœ¬

### 10.2 è¿›åº¦é£é™©ç¼“è§£

**é£é™© 1ï¼šåŠŸèƒ½è”“å»¶**
- ç¼“è§£ï¼šä¸¥æ ¼æŒ‰ P0/P1/P2 ä¼˜å…ˆçº§
- å›é€€ï¼šç æ‰ P2 åŠŸèƒ½

**é£é™© 2ï¼šæµ‹è¯•ä¸å……åˆ†**
- ç¼“è§£ï¼šè¾¹å¼€å‘è¾¹æµ‹è¯•ï¼Œé¢„ç•™æµ‹è¯•æ—¶é—´
- å›é€€ï¼šå‡å°‘åŠŸèƒ½èŒƒå›´

---

**æ–‡æ¡£ç»“æŸ**

**åˆå¹¶æç¤º**: å°†æ­¤æ–‡æ¡£ä¸ `PHASE4_DETAILED_DESIGN.md` åˆå¹¶ï¼Œå½¢æˆå®Œæ•´çš„ Phase 4 è®¾è®¡æ–‡æ¡£ã€‚

**ä¸‹ä¸€æ­¥**: ç­‰å¾…ç”¨æˆ·ç¡®è®¤åå¼€å§‹å®æ–½ Task #26ã€‚
