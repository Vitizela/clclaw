#!/usr/bin/env python3
"""
é‡æ–°ç”Ÿæˆå¸–å­çš„ content.htmlï¼ˆå¸¦ EXIF æ°´å°ï¼‰

ç”¨äºå·²å½’æ¡£çš„å¸–å­ï¼Œåœ¨æå– EXIF åé‡æ–°ç”Ÿæˆ HTML
"""

import sys
import argparse
from pathlib import Path
from datetime import datetime

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

from src.database.connection import get_default_connection
from src.database.models import Post, Media
from src.scraper.archiver import ForumArchiver
from rich.console import Console
from rich.panel import Panel
import yaml

console = Console()


def regenerate_post_html(post_url: str):
    """é‡æ–°ç”ŸæˆæŒ‡å®šå¸–å­çš„ HTML"""

    console.print(Panel.fit(
        "[bold cyan]é‡æ–°ç”Ÿæˆ HTMLï¼ˆå¸¦ EXIF æ°´å°ï¼‰[/bold cyan]",
        border_style="cyan"
    ))
    console.print()

    try:
        # åˆå§‹åŒ–æ•°æ®åº“
        db = get_default_connection()
        if not db.is_initialized():
            console.print("[red]âŒ æ•°æ®åº“æœªåˆå§‹åŒ–[/red]")
            return False

        Post._db = db
        Media._db = db

        # æŸ¥æ‰¾å¸–å­
        console.print(f"ğŸ” æŸ¥æ‰¾å¸–å­: {post_url}")
        post = Post.get_by_url(post_url)

        if not post:
            console.print(f"[red]âŒ æœªæ‰¾åˆ°å¸–å­: {post_url}[/red]")
            return False

        console.print(f"[green]âœ… æ‰¾åˆ°å¸–å­: {post.title}[/green]")
        console.print(f"   è·¯å¾„: {post.file_path}")
        console.print()

        # è·å–å¸–å­ç›®å½•
        post_dir = Path(post.file_path)
        if not post_dir.exists():
            console.print(f"[red]âŒ å¸–å­ç›®å½•ä¸å­˜åœ¨: {post_dir}[/red]")
            return False

        # è·å–å›¾ç‰‡å’Œè§†é¢‘
        images = Media.get_by_post(post.id, media_type='image')
        videos = Media.get_by_post(post.id, media_type='video')

        console.print(f"ğŸ“Š åª’ä½“æ–‡ä»¶:")
        console.print(f"   å›¾ç‰‡: {len(images)} å¼ ")
        console.print(f"   è§†é¢‘: {len(videos)} ä¸ª")

        # ç»Ÿè®¡æœ‰ EXIF çš„å›¾ç‰‡
        exif_count = sum(1 for img in images if img.exif_make)
        if exif_count > 0:
            console.print(f"   [green]EXIF: {exif_count} å¼ [/green]")
        else:
            console.print(f"   [yellow]âš ï¸  æ—  EXIF æ•°æ®ï¼ˆæ°´å°å°†ä¸æ˜¾ç¤ºï¼‰[/yellow]")
        console.print()

        # å‡†å¤‡æ•°æ®
        console.print("ğŸ“ å‡†å¤‡æ•°æ®...")

        # è¯»å– content.txtï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        content = ""
        content_txt = post_dir / 'content.txt'
        if content_txt.exists():
            content = content_txt.read_text(encoding='utf-8')

        # æ„å»º post_data
        post_data = {
            'title': post.title,
            'author': post.author_id,  # éœ€è¦è½¬æ¢ä¸ºä½œè€…å
            'time': post.publish_date or 'N/A',
            'url': post.url,
            'content': content,
            'images': [],
            'videos': []
        }

        # å‡†å¤‡å›¾ç‰‡åˆ—è¡¨ï¼ˆä½¿ç”¨ç›¸å¯¹è·¯å¾„ï¼‰
        for img in images:
            file_path = Path(img.file_path)
            if file_path.name.endswith('.done'):
                file_path = file_path.with_suffix('')

            relative_path = file_path.relative_to(post_dir)
            post_data['images'].append(str(relative_path))

        # å‡†å¤‡è§†é¢‘åˆ—è¡¨
        for vid in videos:
            file_path = Path(vid.file_path)
            if file_path.name.endswith('.done'):
                file_path = file_path.with_suffix('')

            relative_path = file_path.relative_to(post_dir)
            post_data['videos'].append(str(relative_path))

        # è·å–ä½œè€…å
        from src.database.models import Author
        Author._db = db
        author = Author.get_by_id(post.author_id)
        if author:
            post_data['author'] = author.name

        # åˆå§‹åŒ– archiver
        console.print("ğŸ”„ ç”Ÿæˆ HTML...")

        # è¯»å–é…ç½®
        config_file = Path(__file__).parent / 'config.yaml'
        with open(config_file, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)

        archiver = ForumArchiver(config)

        # å¤‡ä»½æ—§ HTML
        old_html = post_dir / 'content.html'
        if old_html.exists():
            backup = post_dir / f'content.html.backup.{datetime.now().strftime("%Y%m%d_%H%M%S")}'
            old_html.rename(backup)
            console.print(f"   å¤‡ä»½æ—§æ–‡ä»¶: {backup.name}")

        # ç”Ÿæˆæ–° HTML
        archiver._save_content_html(post_data, post_dir)

        console.print()
        console.print("[green]âœ… HTML é‡æ–°ç”Ÿæˆå®Œæˆï¼[/green]")
        console.print()
        console.print(f"ğŸ“‚ æ–‡ä»¶è·¯å¾„:")
        console.print(f"   {post_dir / 'content.html'}")
        console.print()

        if exif_count > 0:
            console.print("[green]ğŸ¨ ç°åœ¨æ‰“å¼€ HTML å¯ä»¥çœ‹åˆ° EXIF æ°´å°äº†ï¼[/green]")
            console.print()
            console.print(f"   firefox \"{post_dir / 'content.html'}\"")
        else:
            console.print("[yellow]âš ï¸  è¯¥å¸–å­å›¾ç‰‡æ—  EXIF æ•°æ®ï¼Œæ°´å°ä¸ä¼šæ˜¾ç¤º[/yellow]")

        return True

    except Exception as e:
        console.print(f"[red]âŒ é”™è¯¯: {e}[/red]")
        import traceback
        traceback.print_exc()
        return False


def main():
    parser = argparse.ArgumentParser(
        description="é‡æ–°ç”Ÿæˆå¸–å­çš„ HTMLï¼ˆå¸¦ EXIF æ°´å°ï¼‰"
    )
    parser.add_argument(
        'post_url',
        nargs='?',
        help='å¸–å­ URLï¼ˆå¯é€‰ï¼Œä¸æä¾›åˆ™è‡ªåŠ¨æŸ¥æ‰¾æœ‰ EXIF çš„å¸–å­ï¼‰'
    )

    args = parser.parse_args()

    if args.post_url:
        # é‡æ–°ç”ŸæˆæŒ‡å®šå¸–å­
        regenerate_post_html(args.post_url)
    else:
        # è‡ªåŠ¨æŸ¥æ‰¾å¹¶é‡æ–°ç”Ÿæˆæœ‰ EXIF çš„å¸–å­
        console.print("[cyan]ğŸ” è‡ªåŠ¨æŸ¥æ‰¾æœ‰ EXIF æ•°æ®çš„å¸–å­...[/cyan]\n")

        db = get_default_connection()
        conn = db.get_connection()

        cursor = conn.execute("""
            SELECT DISTINCT p.url, p.title
            FROM posts p
            JOIN media m ON p.id = m.post_id
            WHERE m.type = 'image'
              AND m.exif_make IS NOT NULL
            ORDER BY p.archived_date DESC
            LIMIT 5
        """)

        posts = cursor.fetchall()

        if not posts:
            console.print("[yellow]âŒ æœªæ‰¾åˆ°åŒ…å« EXIF çš„å¸–å­[/yellow]")
            return

        console.print(f"[green]âœ… æ‰¾åˆ° {len(posts)} ä¸ªå¸–å­[/green]\n")

        for i, post in enumerate(posts, 1):
            console.print(f"{i}. {post['title'][:60]}...")
            regenerate_post_html(post['url'])
            console.print("â”€" * 60)
            console.print()


if __name__ == '__main__':
    main()
